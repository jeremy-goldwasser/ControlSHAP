{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper import *\n",
    "from helper_dep import *\n",
    "from helper_indep import *\n",
    "from helper_shapley_sampling import *\n",
    "from helper_kshap import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data\n",
    "## Load Data\n",
    "### Original Dataset\n",
    "- In \"sage\" package (also from Su-in Lee's group)\n",
    "- Has categorical variables with multiple levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Loan</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Prev_Days</th>\n",
       "      <th>Prev_Contacts</th>\n",
       "      <th>Prev_Outcome</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age           Job   Marital  Education Default  Balance Housing Loan  \\\n",
       "0       58    management   married   tertiary      no     2143     yes   no   \n",
       "1       44    technician    single  secondary      no       29     yes   no   \n",
       "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
       "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
       "4       33       unknown    single    unknown      no        1      no   no   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "45206   51    technician   married   tertiary      no      825      no   no   \n",
       "45207   71       retired  divorced    primary      no     1729      no   no   \n",
       "45208   72       retired   married  secondary      no     5715      no   no   \n",
       "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
       "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         Contact  Day Month  Duration  Campaign  Prev_Days  Prev_Contacts  \\\n",
       "0        unknown    5   may       261         1         -1              0   \n",
       "1        unknown    5   may       151         1         -1              0   \n",
       "2        unknown    5   may        76         1         -1              0   \n",
       "3        unknown    5   may        92         1         -1              0   \n",
       "4        unknown    5   may       198         1         -1              0   \n",
       "...          ...  ...   ...       ...       ...        ...            ...   \n",
       "45206   cellular   17   nov       977         3         -1              0   \n",
       "45207   cellular   17   nov       456         2         -1              0   \n",
       "45208   cellular   17   nov      1127         5        184              3   \n",
       "45209  telephone   17   nov       508         4         -1              0   \n",
       "45210   cellular   17   nov       361         2        188             11   \n",
       "\n",
       "      Prev_Outcome  Success  \n",
       "0          unknown    False  \n",
       "1          unknown    False  \n",
       "2          unknown    False  \n",
       "3          unknown    False  \n",
       "4          unknown    False  \n",
       "...            ...      ...  \n",
       "45206      unknown     True  \n",
       "45207      unknown     True  \n",
       "45208      success     True  \n",
       "45209      unknown    False  \n",
       "45210        other    False  \n",
       "\n",
       "[45211 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirpath = \"/Users/jeremygoldwasser/Desktop/SHAP/Data/bank\"\n",
    "# dirpath = /PATH/TO/DATA\n",
    "df_orig = pd.read_csv(join(dirpath, \"df_orig.csv\"))\n",
    "df_orig # 17 columns, so 16 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized Data\n",
    "- Preprocessed so multilevel categorical features get split into multiple columns - one per binary feature\n",
    "- Unsurprisingly, the conditioning number of this matrix is near-infinite; we'll need to address this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Default</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Loan</th>\n",
       "      <th>Day</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Prev_Days</th>\n",
       "      <th>Prev_Contacts</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_jun</th>\n",
       "      <th>Month_mar</th>\n",
       "      <th>Month_may</th>\n",
       "      <th>Month_nov</th>\n",
       "      <th>Month_oct</th>\n",
       "      <th>Month_sep</th>\n",
       "      <th>Prev_Outcome_failure</th>\n",
       "      <th>Prev_Outcome_other</th>\n",
       "      <th>Prev_Outcome_success</th>\n",
       "      <th>Prev_Outcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Default  Balance  Housing  Loan  Day  Duration  Campaign  \\\n",
       "0       58        0     2143        1     0    5       261         1   \n",
       "1       44        0       29        1     0    5       151         1   \n",
       "2       33        0        2        1     1    5        76         1   \n",
       "3       47        0     1506        1     0    5        92         1   \n",
       "4       33        0        1        0     0    5       198         1   \n",
       "...    ...      ...      ...      ...   ...  ...       ...       ...   \n",
       "45206   51        0      825        0     0   17       977         3   \n",
       "45207   71        0     1729        0     0   17       456         2   \n",
       "45208   72        0     5715        0     0   17      1127         5   \n",
       "45209   57        0      668        0     0   17       508         4   \n",
       "45210   37        0     2971        0     0   17       361         2   \n",
       "\n",
       "       Prev_Days  Prev_Contacts  ...  Month_jun  Month_mar  Month_may  \\\n",
       "0             -1              0  ...          0          0          1   \n",
       "1             -1              0  ...          0          0          1   \n",
       "2             -1              0  ...          0          0          1   \n",
       "3             -1              0  ...          0          0          1   \n",
       "4             -1              0  ...          0          0          1   \n",
       "...          ...            ...  ...        ...        ...        ...   \n",
       "45206         -1              0  ...          0          0          0   \n",
       "45207         -1              0  ...          0          0          0   \n",
       "45208        184              3  ...          0          0          0   \n",
       "45209         -1              0  ...          0          0          0   \n",
       "45210        188             11  ...          0          0          0   \n",
       "\n",
       "       Month_nov  Month_oct  Month_sep  Prev_Outcome_failure  \\\n",
       "0              0          0          0                     0   \n",
       "1              0          0          0                     0   \n",
       "2              0          0          0                     0   \n",
       "3              0          0          0                     0   \n",
       "4              0          0          0                     0   \n",
       "...          ...        ...        ...                   ...   \n",
       "45206          1          0          0                     0   \n",
       "45207          1          0          0                     0   \n",
       "45208          1          0          0                     0   \n",
       "45209          1          0          0                     0   \n",
       "45210          1          0          0                     0   \n",
       "\n",
       "       Prev_Outcome_other  Prev_Outcome_success  Prev_Outcome_unknown  \n",
       "0                       0                     0                     1  \n",
       "1                       0                     0                     1  \n",
       "2                       0                     0                     1  \n",
       "3                       0                     0                     1  \n",
       "4                       0                     0                     1  \n",
       "...                   ...                   ...                   ...  \n",
       "45206                   0                     0                     1  \n",
       "45207                   0                     0                     1  \n",
       "45208                   0                     1                     0  \n",
       "45209                   0                     0                     1  \n",
       "45210                   1                     0                     0  \n",
       "\n",
       "[45211 rows x 48 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw = np.load(join(dirpath, \"X_train.npy\"))\n",
    "X_test_raw = np.load(join(dirpath, \"X_test.npy\"))\n",
    "Y_train = np.load(join(dirpath, \"Y_train.npy\"))\n",
    "Y_test = np.load(join(dirpath, \"Y_test.npy\"))\n",
    "full_dim = X_train_raw.shape[1] # dimension including all binarized categorical columns\n",
    "X_df = pd.read_csv(join(dirpath, \"X_df.csv\"))\n",
    "\n",
    "xloc_raw = X_test_raw[0].reshape((1,full_dim))\n",
    "\n",
    "X_df # 48-dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mean-zero unit-variance\n",
    "trainmean, trainstd = np.mean(X_train_raw, axis=0), np.std(X_train_raw, axis=0)\n",
    "def rescale(x, trainmean, trainstd):\n",
    "    return (x - trainmean) / trainstd\n",
    "X_train = rescale(X_train_raw, trainmean, trainstd)\n",
    "X_test = rescale(X_test_raw, trainmean, trainstd)\n",
    "xloc = rescale(xloc_raw, trainmean, trainstd)\n",
    "\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = np.cov(X_train, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for dealing with multilevel columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0],\n",
       " 1: [1],\n",
       " 2: [2],\n",
       " 3: [3],\n",
       " 4: [4],\n",
       " 5: [5],\n",
       " 6: [6],\n",
       " 7: [7],\n",
       " 8: [8],\n",
       " 9: [9],\n",
       " 10: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21],\n",
       " 11: [22, 23, 24],\n",
       " 12: [25, 26, 27, 28],\n",
       " 13: [29, 30, 31],\n",
       " 14: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43],\n",
       " 15: [44, 45, 46, 47]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig.columns = df_orig.columns.str.replace(' ', '_')\n",
    "categorical_cols = ['Job', 'Marital', 'Education', 'Default', 'Housing',\n",
    "                    'Loan', 'Contact', 'Month', 'Prev_Outcome']\n",
    "mapping_dict = get_mapping_dict(df_orig, X_df, X_train_raw, categorical_cols)\n",
    "mapping_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network class & instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "class ThreeLayerNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(ThreeLayerNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.linear3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn dataset into Pytorch iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the input and label data to PyTorch tensors\n",
    "inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels = torch.tensor(Y_train, dtype=torch.long)\n",
    "\n",
    "# Compute the class weights\n",
    "class_counts = torch.bincount(labels)\n",
    "num_samples = len(labels)\n",
    "class_weights = 1.0 / class_counts.float()\n",
    "sample_weights = class_weights[labels]\n",
    "\n",
    "# Create a sampler with balanced weights\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=num_samples, replacement=True)\n",
    "\n",
    "# Create a DataLoader with the sampler\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6461\n",
      "Epoch 2/5, Loss: 0.4329\n",
      "Epoch 3/5, Loss: 0.3161\n",
      "Epoch 4/5, Loss: 0.3915\n",
      "Epoch 5/5, Loss: 0.3143\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Create an instance\n",
    "net = TwoLayerNet(input_size=full_dim, hidden_size=50, output_size=2)\n",
    "# net = ThreeLayerNet(input_size=full_dim, hidden_size1=50, hidden_size2=50, output_size=2)\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()#weight=torch.tensor(weights)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)#.01\n",
    "\n",
    "# Iterate over the training data in batches\n",
    "num_epochs = 5\n",
    "\n",
    "# Train the network for the specified number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        # Zero the gradients for this batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the forward pass of the network\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Compute the loss for this batch\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute the gradients of the loss with respect to the parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters using the optimizer\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute training outputs and errors\n",
    "- Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130/4521 predictions are for positive class; really 529\n",
      "Balanced sampling. 84% accuracy\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(test_tensor)\n",
    "\n",
    "n_test = X_test.shape[0]\n",
    "n_positive_preds = torch.sum(np.argmax(outputs, axis=1)==1).item()\n",
    "print(\"{}/{} predictions are for positive class; really {}\"\n",
    "    .format(n_positive_preds,n_test, np.sum(Y_test==1)))\n",
    "Y_preds = torch.argmax(outputs, axis=1)\n",
    "print(\"Balanced sampling. {}% accuracy\".format(round(100*(np.sum(Y_test==Y_preds.numpy())/n_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Gradient and Hessian of neural net w.r.t. input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xloc_torch = torch.tensor(xloc, dtype=torch.float32).requires_grad_(True)\n",
    "y_pred = net(xloc_torch)[0,1]\n",
    "y_pred.backward()\n",
    "gradient = xloc_torch.grad.detach().numpy().reshape((full_dim, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(x):\n",
    "    output = net(x)[0,1] if x.shape[0]==1 else net(x)[:,1]\n",
    "    return output\n",
    "\n",
    "def compute_hessian(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    hessian = torch.autograd.functional.hessian(neural_net, x)\n",
    "    hessian = hessian.reshape((full_dim,full_dim)).detach().numpy()\n",
    "    return hessian\n",
    "\n",
    "hessian = compute_hessian(xloc)\n",
    "def f_model(x):\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "    return neural_net(x).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assume Feature Independence\n",
    "## Show true SHAP values of quadratic approximation are sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25914243 2.3152832962929017\n",
      "xloc prediction:  0.07519988\n",
      "Expected CV:\tf(X)-Ef(X) =  -2.240083416586996\n",
      "sum of true CV SHAP vals =  -2.240146744530648\n"
     ]
    }
   ],
   "source": [
    "independent_features = True\n",
    "avg_pred_model, avg_pred_CV = compute_avg_preds(f_model, X_train, xloc, independent_features, gradient, hessian)\n",
    "print(avg_pred_model, avg_pred_CV) # Uh oh, average pred of linear model is outside of [0,1]\n",
    "\n",
    "shap_CV_true_indep = compute_true_shap_cv_indep(xloc, gradient, hessian, feature_means, cov_mat, mapping_dict)\n",
    "sum_shap_CV_true = np.sum(shap_CV_true_indep)\n",
    "pred = f_model(xloc)\n",
    "\n",
    "expected_model = pred - avg_pred_model\n",
    "expected_CV = pred - avg_pred_CV\n",
    "print(\"xloc prediction: \", pred)\n",
    "print(\"Expected CV:\\tf(X)-Ef(X) = \", expected_CV)\n",
    "print('sum of true CV SHAP vals = ', sum_shap_CV_true) # Pretty close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Sampling, assuming independent features\n",
    "(Theoretical) variance reductions are OK, not terribly impressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32  0.08  0.15  0.28  0.42  0.11  0.27  0.15  0.05  0.62  0.29 -0.09\n",
      "  0.47  0.08  0.17 -0.09  0.17  0.28 -0.15 -0.16  0.27  0.34  0.11  0.4\n",
      "  0.39  0.36  0.43  0.39  0.16  0.5   0.32  0.59  0.17  0.63  0.84  0.28\n",
      "  0.28  0.43  0.44  0.39  0.36  0.37  0.19  0.58  0.08 -0.23  0.18  0.12]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "independent_features = True\n",
    "obj_ss = cv_shapley_sampling(f_model, X_train, xloc, \n",
    "                        independent_features,\n",
    "                        gradient, hessian,\n",
    "                        M=100, n_samples_per_perm=10) # M is number of permutations)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_ss\n",
    "print(np.round(corr_ests,2)) # Relatively weak correlations; sometimes negative\n",
    "plt.hist(corr_ests**2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP, assuming independent features\n",
    "Similar variance reductions; maybe a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25  0.52  0.25  0.13  0.32  0.48  0.36  0.23  0.3   0.32  0.3   0.18\n",
      "  0.38  0.67  0.23  0.45  0.2   0.31 -0.08  0.42  0.09  0.42  0.44  0.63\n",
      " -0.01  0.67  0.24  0.66  0.5   0.28  0.55  0.37  0.11  0.01  0.45  0.04\n",
      "  0.25  0.7   0.39  0.56  0.39  0.01  0.62  0.35  0.55  0.31  0.47  0.49]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "obj_kshap = cv_kshap(f_model, X_train, xloc, \n",
    "            independent_features,\n",
    "            gradient, hessian,\n",
    "            M=2000, n_samples_per_perm=10)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap\n",
    "print(np.round(corr_ests,2)) # Pretty weak correlations; sometimes negative\n",
    "plt.hist(corr_ests**2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependent Features\n",
    "\n",
    "## Recondition covariance, then estimate matrices for Control Variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u, s, vh = np.linalg.svd(cov_mat, full_matrices=True)\n",
    "K = 10000\n",
    "s_max = s[0]\n",
    "min_acceptable = s_max/K\n",
    "s2 = np.copy(s)\n",
    "s2[s <= min_acceptable] = min_acceptable\n",
    "cov2 = np.matmul(u, np.matmul(np.diag(s2), vh))\n",
    "\n",
    "M_linear = 1000 # 10 seconds/1000 perms or so\n",
    "D_matrices = make_all_lundberg_matrices(M_linear, cov2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute almost-true SHAP values of linear model; verify their sum is close to $f(x)-Ef(X)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17215737223727684\n",
      "0.17422887123629013\n"
     ]
    }
   ],
   "source": [
    "avg_CV_empirical = np.mean(f_first_order_approx(f_model,X_train, xloc, gradient))\n",
    "pred = f_model(xloc)\n",
    "exp_CV_sum_empirical = pred - avg_CV_empirical\n",
    "\n",
    "avg_model_empirical = np.mean(f_model(X_train))\n",
    "exp_model_sum_empirical = pred - avg_model_empirical\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient)\n",
    "sum_shap_CV_true = np.sum(shap_CV_true_dep)\n",
    "print(exp_CV_sum_empirical)\n",
    "print(sum_shap_CV_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Sampling, assuming dependent features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "independent_features = False\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient)\n",
    "obj_dep = cv_shapley_sampling(f_model, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient, # Don't need to give hessian, since CV is linear model \n",
    "                    shap_CV_true=shap_CV_true_dep, # Equivalently, can give D_matrices instead\n",
    "                    M=100,n_samples_per_perm=10)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_dep\n",
    "print(corr_ests)\n",
    "print(rank_shap(final_ests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP values, assuming dependent features\n",
    "- Recall default method for variance estimation is bootstrapping w/ 250 resamplings.\n",
    "    - For the sake of brevity, I won't show alternatives again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93951184 0.94745438 0.94722257 0.94507995 0.92577878 0.94052093\n",
      " 0.93404105 0.92126558 0.92333779 0.92353307]\n",
      "[5 3 4 7 6 9 0 2 1 8]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "obj_kshap_dep = cv_kshap(f_model, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    shap_CV_true=shap_CV_true_dep,\n",
    "                    M=1000,n_samples_per_perm=10)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap_dep\n",
    "print(corr_ests)\n",
    "print(rank_shap(final_ests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
