{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from helper import *\n",
    "# from helper_dep import *\n",
    "# from helper_indep import *\n",
    "# from helper_shapley_sampling import *\n",
    "# from helper_kshap import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sage\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Marital</th>\n",
       "      <th>Education</th>\n",
       "      <th>Default</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Loan</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Prev_Days</th>\n",
       "      <th>Prev_Contacts</th>\n",
       "      <th>Prev_Outcome</th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age           Job   Marital  Education Default  Balance Housing Loan  \\\n",
       "0       58    management   married   tertiary      no     2143     yes   no   \n",
       "1       44    technician    single  secondary      no       29     yes   no   \n",
       "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
       "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
       "4       33       unknown    single    unknown      no        1      no   no   \n",
       "...    ...           ...       ...        ...     ...      ...     ...  ...   \n",
       "45206   51    technician   married   tertiary      no      825      no   no   \n",
       "45207   71       retired  divorced    primary      no     1729      no   no   \n",
       "45208   72       retired   married  secondary      no     5715      no   no   \n",
       "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
       "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
       "\n",
       "         Contact  Day Month  Duration  Campaign  Prev_Days  Prev_Contacts  \\\n",
       "0        unknown    5   may       261         1         -1              0   \n",
       "1        unknown    5   may       151         1         -1              0   \n",
       "2        unknown    5   may        76         1         -1              0   \n",
       "3        unknown    5   may        92         1         -1              0   \n",
       "4        unknown    5   may       198         1         -1              0   \n",
       "...          ...  ...   ...       ...       ...        ...            ...   \n",
       "45206   cellular   17   nov       977         3         -1              0   \n",
       "45207   cellular   17   nov       456         2         -1              0   \n",
       "45208   cellular   17   nov      1127         5        184              3   \n",
       "45209  telephone   17   nov       508         4         -1              0   \n",
       "45210   cellular   17   nov       361         2        188             11   \n",
       "\n",
       "      Prev_Outcome  Success  \n",
       "0          unknown    False  \n",
       "1          unknown    False  \n",
       "2          unknown    False  \n",
       "3          unknown    False  \n",
       "4          unknown    False  \n",
       "...            ...      ...  \n",
       "45206      unknown     True  \n",
       "45207      unknown     True  \n",
       "45208      success     True  \n",
       "45209      unknown    False  \n",
       "45210        other    False  \n",
       "\n",
       "[45211 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Success\" column is output\n",
    "df_orig = sage.datasets.bank()\n",
    "df_orig.columns = df_orig.columns.str.replace(' ', '_')\n",
    "feature_names = df_orig.columns.tolist()[:-1]\n",
    "categorical_cols = ['Job', 'Marital', 'Education', 'Default', 'Housing',\n",
    "                    'Loan', 'Contact', 'Month', 'Prev_Outcome']\n",
    "categorical_inds = [feature_names.index(col) for col in categorical_cols]\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 3, 4, 2, 2, 2, 3, 12, 4]\n",
      "Job\n",
      "['management' 'technician' 'entrepreneur' 'blue-collar' 'unknown'\n",
      " 'retired' 'admin.' 'services' 'self-employed' 'unemployed' 'housemaid'\n",
      " 'student']\n",
      "Marital\n",
      "['married' 'single' 'divorced']\n",
      "Education\n",
      "['tertiary' 'secondary' 'unknown' 'primary']\n",
      "Default\n",
      "['no' 'yes']\n",
      "Housing\n",
      "['yes' 'no']\n",
      "Loan\n",
      "['no' 'yes']\n",
      "Contact\n",
      "['unknown' 'cellular' 'telephone']\n",
      "Month\n",
      "['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'jan' 'feb' 'mar' 'apr' 'sep']\n",
      "Prev_Outcome\n",
      "['unknown' 'failure' 'other' 'success']\n"
     ]
    }
   ],
   "source": [
    "# Change to binary so we can use sklearn classifiers. gradient boosting produces 0 derivatives so don't want to use\n",
    "n_levels = [len(df_orig[col].unique()) for col in categorical_cols]\n",
    "print(n_levels)\n",
    "for col in df_orig:\n",
    "    if col in categorical_cols:\n",
    "        print(col)\n",
    "        print(df_orig[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change columns to binary\n",
    "df = df_orig.copy()\n",
    "jobs = pd.get_dummies(df.Job, prefix='Job')\n",
    "df = df.join(jobs)\n",
    "df.drop(['Job'], axis=1, inplace=True)\n",
    "\n",
    "marital = pd.get_dummies(df.Marital, prefix='Marital')\n",
    "df = df.join(marital)\n",
    "df.drop(['Marital'], axis=1, inplace=True)\n",
    "\n",
    "Education = pd.get_dummies(df.Education, prefix='Education')\n",
    "df = df.join(Education)\n",
    "df.drop(['Education'], axis=1, inplace=True)\n",
    "\n",
    "Contact = pd.get_dummies(df.Contact, prefix='Contact')\n",
    "df = df.join(Contact)\n",
    "df.drop(['Contact'], axis=1, inplace=True)\n",
    "\n",
    "Month = pd.get_dummies(df.Month, prefix='Month')\n",
    "df = df.join(Month)\n",
    "df.drop(['Month'], axis=1, inplace=True)\n",
    "\n",
    "prev_outcome = pd.get_dummies(df[\"Prev_Outcome\"], prefix='Prev_Outcome')\n",
    "df = df.join(prev_outcome)\n",
    "df.drop(['Prev_Outcome'], axis=1, inplace=True)\n",
    "\n",
    "df.Default = df.Default.map({'no': 0, 'yes': 1})\n",
    "df.Housing = df.Housing.map({'no': 0, 'yes': 1})\n",
    "df.Loan = df.Loan.map({'no': 0, 'yes': 1})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Default</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Loan</th>\n",
       "      <th>Day</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Prev_Days</th>\n",
       "      <th>Prev_Contacts</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_jun</th>\n",
       "      <th>Month_mar</th>\n",
       "      <th>Month_may</th>\n",
       "      <th>Month_nov</th>\n",
       "      <th>Month_oct</th>\n",
       "      <th>Month_sep</th>\n",
       "      <th>Prev_Outcome_failure</th>\n",
       "      <th>Prev_Outcome_other</th>\n",
       "      <th>Prev_Outcome_success</th>\n",
       "      <th>Prev_Outcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1506</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Default  Balance  Housing  Loan  Day  Duration  Campaign  \\\n",
       "0       58        0     2143        1     0    5       261         1   \n",
       "1       44        0       29        1     0    5       151         1   \n",
       "2       33        0        2        1     1    5        76         1   \n",
       "3       47        0     1506        1     0    5        92         1   \n",
       "4       33        0        1        0     0    5       198         1   \n",
       "...    ...      ...      ...      ...   ...  ...       ...       ...   \n",
       "45206   51        0      825        0     0   17       977         3   \n",
       "45207   71        0     1729        0     0   17       456         2   \n",
       "45208   72        0     5715        0     0   17      1127         5   \n",
       "45209   57        0      668        0     0   17       508         4   \n",
       "45210   37        0     2971        0     0   17       361         2   \n",
       "\n",
       "       Prev_Days  Prev_Contacts  ...  Month_jun  Month_mar  Month_may  \\\n",
       "0             -1              0  ...          0          0          1   \n",
       "1             -1              0  ...          0          0          1   \n",
       "2             -1              0  ...          0          0          1   \n",
       "3             -1              0  ...          0          0          1   \n",
       "4             -1              0  ...          0          0          1   \n",
       "...          ...            ...  ...        ...        ...        ...   \n",
       "45206         -1              0  ...          0          0          0   \n",
       "45207         -1              0  ...          0          0          0   \n",
       "45208        184              3  ...          0          0          0   \n",
       "45209         -1              0  ...          0          0          0   \n",
       "45210        188             11  ...          0          0          0   \n",
       "\n",
       "       Month_nov  Month_oct  Month_sep  Prev_Outcome_failure  \\\n",
       "0              0          0          0                     0   \n",
       "1              0          0          0                     0   \n",
       "2              0          0          0                     0   \n",
       "3              0          0          0                     0   \n",
       "4              0          0          0                     0   \n",
       "...          ...        ...        ...                   ...   \n",
       "45206          1          0          0                     0   \n",
       "45207          1          0          0                     0   \n",
       "45208          1          0          0                     0   \n",
       "45209          1          0          0                     0   \n",
       "45210          1          0          0                     0   \n",
       "\n",
       "       Prev_Outcome_other  Prev_Outcome_success  Prev_Outcome_unknown  \n",
       "0                       0                     0                     1  \n",
       "1                       0                     0                     1  \n",
       "2                       0                     0                     1  \n",
       "3                       0                     0                     1  \n",
       "4                       0                     0                     1  \n",
       "...                   ...                   ...                   ...  \n",
       "45206                   0                     0                     1  \n",
       "45207                   0                     0                     1  \n",
       "45208                   0                     1                     0  \n",
       "45209                   0                     0                     1  \n",
       "45210                   1                     0                     0  \n",
       "\n",
       "[45211 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, test = train_test_split(\n",
    "    df.values, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "train, val = train_test_split(\n",
    "    train, test_size=int(0.1 * len(df.values)), random_state=123)\n",
    "# Y_train = train[:, -1].copy().astype(int)\n",
    "# Y_val = val[:, -1].copy().astype(int)\n",
    "# Y_test = test[:, -1].copy().astype(int)\n",
    "# train = train[:, :-1].copy()\n",
    "# val = val[:, :-1].copy()\n",
    "# test = test[:, :-1].copy()\n",
    "\n",
    "suc_idx = df.columns.get_loc(\"Success\")\n",
    "Y_train = train[:, suc_idx].copy().astype(int)\n",
    "Y_val = val[:, suc_idx].copy().astype(int)\n",
    "Y_test = test[:, suc_idx].copy().astype(int)\n",
    "X_train = np.delete(train, suc_idx, axis=1).astype(\"float64\")\n",
    "X_val = np.delete(val, suc_idx, axis=1).astype(\"float64\")\n",
    "X_test = np.delete(test, suc_idx, axis=1).astype(\"float64\")\n",
    "\n",
    "n_train, d_binarized = X_train.shape\n",
    "d_orig = len(feature_names)\n",
    "d_orig\n",
    "\n",
    "# X_train is a np array with no labels, but it mostly aligns with df\n",
    "# The only difference is that df has the target column with index suc_idx\n",
    "X_df = df.copy()\n",
    "X_df.drop(['Success'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 'ordinal',\n",
       " 'Job': 'multilevel',\n",
       " 'Marital': 'multilevel',\n",
       " 'Education': 'multilevel',\n",
       " 'Default': 'binary',\n",
       " 'Balance': 'ordinal',\n",
       " 'Housing': 'binary',\n",
       " 'Loan': 'binary',\n",
       " 'Contact': 'multilevel',\n",
       " 'Day': 'ordinal',\n",
       " 'Month': 'multilevel',\n",
       " 'Duration': 'ordinal',\n",
       " 'Campaign': 'ordinal',\n",
       " 'Prev_Days': 'ordinal',\n",
       " 'Prev_Contacts': 'ordinal',\n",
       " 'Prev_Outcome': 'multilevel'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make vector listing type of each columnn (ignoring binary structure)\n",
    "types = [None]*d_orig\n",
    "for j in range(d_orig):\n",
    "    if j in categorical_inds:\n",
    "        idx_in_categorical_inds = np.argwhere(np.array(categorical_inds)==j).item()\n",
    "        n_lev = n_levels[idx_in_categorical_inds]\n",
    "        if n_lev==2:\n",
    "            types[j] = \"binary\"\n",
    "        else:\n",
    "            types[j] = \"multilevel\"\n",
    "    else:\n",
    "        unique_vals = np.unique(X_train[:,j]).astype(float)\n",
    "        vals_minus_int = unique_vals - np.round(unique_vals)\n",
    "        is_not_ordinal = np.sum(vals_minus_int != 0)\n",
    "        if is_not_ordinal:\n",
    "            types[j] = \"continuous\"\n",
    "        else:\n",
    "            types[j] = \"ordinal\"\n",
    "\n",
    "types_dict = {}\n",
    "for i in range(len(feature_names)):\n",
    "    types_dict.update({feature_names[i]: types[i]})\n",
    "types_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting model\n",
    "\n",
    "Original model is gradient tree boosting. Trees have flat gradients locally, though, so it's harder to choose hyperparameters that will yield a nonzero gradient. For now, then, focusing on models that aren't piecewise. sklearn requires categorical features to be encoded as binary, which is why we do the whole annoying one-hot encoding schema.<br>\n",
    "\n",
    "Specifically, looking at logistic regression. This works even when the matrix has binary columns for each variable\n",
    "and thus is not full-rankâ€¦ I think this is because it fits without an intercept term<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 (1, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.96098469, 0.03901531],\n",
       "       [0.95188175, 0.04811825],\n",
       "       [0.84721359, 0.15278641],\n",
       "       ...,\n",
       "       [0.24673047, 0.75326953],\n",
       "       [0.94507287, 0.05492713],\n",
       "       [0.94877249, 0.05122751]])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train, Y_train)\n",
    "print(X_train.shape[1], model.coef_.shape)\n",
    "model.predict_proba(X_test)\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# model = MLPClassifier().fit(X_train, Y_train)\n",
    "# Also tried running w neural network & it seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification test-set accuracy, Logistic regression: 0.900464499004645\n",
      "[False]\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "# Overall good! but model messes up on test set index 0, so set index 1 as xloc.\n",
    "print(\"Classification test-set accuracy, Logistic regression: {}\".format(np.mean(model.predict(X_test)==Y_test)))\n",
    "for i in range(2):\n",
    "    print(Y_test[i]==model.predict(X_test[i].reshape((1,-1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First & Second Derivatives w.r.t. ordinal feature\n",
    "### First derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right off the bat, compute the true gradient and Hessian of our logistic regression model\n",
    "xloc = X_test[1].reshape((1,-1))\n",
    "gradient = grad_at_xloc(xloc, model.coef_.reshape(-1))\n",
    "H = hessian(xloc, model.coef_.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48,)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Package doesn't work here\n",
    "import numdifftools as nd\n",
    "def model_prob(x):\n",
    "    return model.predict_proba(xloc)[0,1]\n",
    "H_package = nd.Hessian(model_prob)(xloc.reshape(-1))\n",
    "print(np.max(H_package))\n",
    "grad_package = nd.Gradient(model_prob)(xloc.reshape(-1))\n",
    "print(np.max(grad_package))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "0 Age\n"
     ]
    }
   ],
   "source": [
    "# Identify j = index of an ordinal column in X_train/X_test/xloc \n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"ordinal\":\n",
    "        ordinal_colname = col\n",
    "        print(ordinal_colname)\n",
    "        break\n",
    "# Find index of this column in X_df, and thus X_train\n",
    "j = np.nonzero(X_df.columns==ordinal_colname)[0].item()\n",
    "print(j, ordinal_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -0.0001099012\n",
      "1000 -0.000109859\n",
      "100 -0.0001098659\n",
      "10 -0.0001098755\n",
      "-0.00020932811416722195\n"
     ]
    }
   ],
   "source": [
    "Ks = [10000, 1000, 100, 10] # Very stable wrt K here\n",
    "n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "\n",
    "for K in Ks:\n",
    "    # Find indices of K rows of X whose j'th column is closest - but not zero - to xloc's.\n",
    "    idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "    xj_vals = X_train[idx, j]\n",
    "    values, counts = np.unique(xj_vals, return_counts=True)\n",
    "    der_ests = [0]*len(values)\n",
    "    for i in range(len(values)):\n",
    "        h = values[i] - xloc[0][j]\n",
    "        xloc_plus_h = np.copy(xloc)\n",
    "        xloc_plus_h[0][j] += h\n",
    "        der_ests[i] = (model.predict_proba(xloc_plus_h)[0,1] - model.predict_proba(xloc)[0,1])/h\n",
    "    derivative = np.sum(der_ests * counts/sum(counts)) # Weighted sum\n",
    "    print(K, np.round(derivative, 10))\n",
    "\n",
    "# Reality check this against true derivative. Off by a factor of 2... not amazing but not too bad.\n",
    "print(gradient[j].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.00010997069403059084, -0.00010973258571649047]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.hist(np.array(der_ests))\n",
    "der_ests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2.3810862245845233e-07\n",
      "1000 2.3810831410037148e-07\n",
      "100 2.3810831410037148e-07\n",
      "10 2.3810831410037148e-07\n",
      "4.050341213174342e-07\n"
     ]
    }
   ],
   "source": [
    "xloc = X_test[1].reshape((1,-1))\n",
    "Ks = [10000, 1000, 100, 10] # Very stable wrt K here\n",
    "n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "\n",
    "for K in Ks:\n",
    "    # Find indices of K rows of X whose j'th column is closest - but not zero - to xloc's.\n",
    "    idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "    xj_vals = X_train[idx, j]\n",
    "    values, counts = np.unique(xj_vals, return_counts=True)\n",
    "    np.unique(xj_vals, return_counts=True)\n",
    "    second_der_ests = [0]*len(values)\n",
    "    for i in range(len(values)):\n",
    "        h = values[i] - xloc[0][j]\n",
    "        xloc_plus_h = np.copy(xloc)\n",
    "        xloc_plus_h[0][j] += h\n",
    "        xloc_minus_h = np.copy(xloc)\n",
    "        xloc_minus_h[0][j] -= h\n",
    "        second_der_ests[i] = (model.predict_proba(xloc_plus_h)[0,1] \n",
    "                        - 2*model.predict_proba(xloc)[0,1] \n",
    "                        + model.predict_proba(xloc_minus_h)[0,1])/(h**2)\n",
    "    second_derivative = np.sum(second_der_ests * counts/sum(counts)) # Weighted sum\n",
    "    print(K, second_derivative)\n",
    "\n",
    "\n",
    "# Reality check this against true second derivative. Again, off by a factor of 2... not amazing but not too bad.\n",
    "print(H[j,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3810831410037148e-07, 2.3810831410037148e-07]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_der_ests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Derivative w.r.t. binary feature\n",
    "second derivative of a categorical variable = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default\n",
      "1 Default\n"
     ]
    }
   ],
   "source": [
    "# Identify j = index of a binary column in X_train/X_test/xloc \n",
    "# hard because our data structure storing data type is with the whole variable, \n",
    "# whereas X_train has been split into multiple columns due to the multilevel variables\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"binary\":\n",
    "        binary_colname = col\n",
    "        print(binary_colname)\n",
    "        break\n",
    "# Find index of this binary column in X_train\n",
    "j = np.nonzero(X_df.columns==binary_colname)[0].item()\n",
    "print(j, binary_colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.003708302194235305\n",
      "-0.0073390351949339\n"
     ]
    }
   ],
   "source": [
    "xloc_feature_on, xloc_feature_off = np.copy(xloc), np.copy(xloc)\n",
    "xloc_feature_off[0][j] = 0\n",
    "xloc_feature_on[0][j] = 1\n",
    "der = model.predict_proba(xloc_feature_on)[0,1] - model.predict_proba(xloc_feature_off)[0,1]\n",
    "print(der)\n",
    "print(gradient[j].item()) # Again, off by a factor of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Derivative w.r.t. Multilevel Categorical Feature\n",
    "### Single derivative\n",
    "\n",
    "afaik no great way to validate this, since automatically computing derivative would be wrt all binary columns, not the single column representing Jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job', 'Marital', 'Education', 'Contact', 'Month', 'Prev_Outcome']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_multilevel_features():\n",
    "    multilevel_feats = []\n",
    "    for key, value in types_dict.items():\n",
    "        if value==\"multilevel\":\n",
    "            multilevel_feats.append(key)\n",
    "    return multilevel_feats\n",
    "\n",
    "get_multilevel_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0038798922119870445"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"multilevel\":\n",
    "        multilevel_colname = col\n",
    "        print(multilevel_colname)\n",
    "        break\n",
    "\n",
    "# Find the indices corresponding to multilevel feature (job) in X_df\n",
    "indices_of_col = np.nonzero(X_df.columns.str.startswith(multilevel_colname))[0]\n",
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_j = len(indices_of_col)\n",
    "der_ests = []#[0]*(n_levels_j-1)\n",
    "for i in range(n_levels_j):\n",
    "    if i != level:\n",
    "        xloc_chg = np.copy(xloc)\n",
    "        chgd_factor = np.zeros(n_levels_j)\n",
    "        chgd_factor[i] = 1\n",
    "        xloc_chg[0][indices_of_col] = chgd_factor\n",
    "        der_ests.append(model.predict_proba(xloc_chg)[0,1] - model.predict_proba(xloc)[0,1])\n",
    "derivative = np.mean(der_ests)\n",
    "derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01000745])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Derivative of that feature level. Opposite sign :( concerning\n",
    "k = indices_of_col[level]\n",
    "gradient[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 4., 2., 1., 1., 1., 0., 0., 0., 1.]),\n",
       " array([-0.01027155, -0.00567056, -0.00106957,  0.00353142,  0.00813241,\n",
       "         0.0127334 ,  0.01733439,  0.02193538,  0.02653637,  0.03113736,\n",
       "         0.03573835]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.array(der_ests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.011863807005246162,\n",
       " -0.010271552120080657,\n",
       " -0.003615571649206964,\n",
       " -0.002138551833722621,\n",
       " 0,\n",
       " 0.03573835096274598,\n",
       " -0.0008832796780694832,\n",
       " -0.005323456082368561,\n",
       " 0.015954360293033723,\n",
       " -0.004140807956118785,\n",
       " 0.0017164024498111247,\n",
       " 0.0037791129405875673]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"multilevel\":\n",
    "        multilevel_colname = col\n",
    "        print(multilevel_colname)\n",
    "        break\n",
    "\n",
    "# Find the indices corresponding to multilevel feature (job) in X_df\n",
    "indices_of_col = np.nonzero(X_df.columns.str.startswith(multilevel_colname))[0]\n",
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_j = len(indices_of_col)\n",
    "gradient_categorical = []\n",
    "for i in range(n_levels_j):\n",
    "    if i != level:\n",
    "        xloc_chg = np.copy(xloc)\n",
    "        # xloc_chg[0][indices_of_col[i]] += 0.001\n",
    "        chgd_factor = np.zeros(n_levels_j)\n",
    "        chgd_factor[i] = 1\n",
    "        xloc_chg[0][indices_of_col] = chgd_factor\n",
    "        gradient_categorical.append((model.predict_proba(xloc_chg)[0,1] - model.predict_proba(xloc)[0,1]))\n",
    "    else:\n",
    "        gradient_categorical.append(0)\n",
    "gradient_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01  -0.032 -0.017 -0.014 -0.01   0.042 -0.012 -0.021  0.016 -0.018\n",
      "  -0.007 -0.003]]\n",
      "[ 0.012 -0.01  -0.004 -0.002  0.     0.036 -0.001 -0.005  0.016 -0.004\n",
      "  0.002  0.004]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9934238789821731"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.round(gradient[indices_of_col].T, 3))\n",
    "print(np.round(gradient_categorical, 3))\n",
    "np.corrcoef(np.array(gradient_categorical), gradient[indices_of_col].reshape(-1))[0,1] # Very highly correlated! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessian Off-Diagonals $\\frac{\\partial^2 f}{\\partial x_j \\partial x_k}$\n",
    "## Same Type\n",
    "### Both ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Age\n",
      "2 Balance\n"
     ]
    }
   ],
   "source": [
    "# Identify j, k = index of ordinal columns in X_train/X_test/xloc \n",
    "ord1 = None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"ordinal\":\n",
    "        if ord1 is None:\n",
    "            ord1 = col\n",
    "        else:\n",
    "            ord2 = col\n",
    "            break\n",
    "\n",
    "# Find index of these columns in X_train\n",
    "X_df = df.copy()\n",
    "X_df.drop(['Success'], axis=1, inplace=True)\n",
    "j = np.nonzero(X_df.columns==ord1)[0].item()\n",
    "k = np.nonzero(X_df.columns==ord2)[0].item()\n",
    "print(j, ord1)\n",
    "print(k, ord2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -1.4149445046454077e-09\n",
      "1000 -1.415047714144431e-09\n",
      "100 -1.4151280870710232e-09\n",
      "10 -1.415235954815852e-09\n",
      "-2.4069259986119463e-09\n"
     ]
    }
   ],
   "source": [
    "Ks = [10000, 1000, 100, 10]\n",
    "n_equal_j = np.sum(X_train[:,j] == xloc[0,j])\n",
    "n_equal_k = np.sum(X_train[:,k] == xloc[0,k])\n",
    "idx_dists_ordered_j = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "idx_dists_ordered_k = np.argsort(np.abs(X_train[:,k] - xloc[0,k]))\n",
    "\n",
    "for K in Ks:\n",
    "    # Find indices of K rows of X whose j'th column is closest - but not zero - to xloc's.\n",
    "    idx_j = idx_dists_ordered_j[n_equal_j:(n_equal_j+K)]\n",
    "    idx_k = idx_dists_ordered_k[n_equal_k:(n_equal_k+K)]\n",
    "    xj_vals = X_train[idx_j, j]\n",
    "    xk_vals = X_train[idx_k, k]\n",
    "    values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "    values_k, counts_k = np.unique(xk_vals, return_counts=True)\n",
    "    n_unique_j = values_j.shape[0]\n",
    "    n_unique_k = values_k.shape[0]\n",
    "    der_ests = []\n",
    "    weights = []\n",
    "    for a in range(n_unique_j):\n",
    "        jval, nj = values_j[a], counts_j[a]\n",
    "        hj = jval - xloc[0][j]\n",
    "        xloc_plus_hj = np.copy(xloc)\n",
    "        xloc_plus_hj[0][j] += hj\n",
    "        \n",
    "        for b in range(n_unique_k):\n",
    "            kval, nk = values_k[b], counts_k[b]\n",
    "            hk = kval - xloc[0][k]\n",
    "            xloc_plus_hk = np.copy(xloc)\n",
    "            xloc_plus_hk[0][k] += hk\n",
    "            xloc_plus_hj_hk = np.copy(xloc_plus_hj)\n",
    "            xloc_plus_hj_hk[0][k] += hk\n",
    "            der_ests.append((model.predict_proba(xloc_plus_hj_hk)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hk)[0,1]+\n",
    "                            model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "            weights.append((nj*nk)/(K**2))\n",
    "    H_jk = np.sum(der_ests * np.array(weights)) # Weighted sum\n",
    "    print(K, H_jk)\n",
    "print(H[j,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Default\n",
      "3 Housing\n"
     ]
    }
   ],
   "source": [
    "# Identify j, k = index of ordinal columns in X_train/X_test/xloc \n",
    "bin1 = None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"binary\":\n",
    "        if bin1 is None:\n",
    "            bin1 = col\n",
    "        else:\n",
    "            bin2 = col\n",
    "            break\n",
    "\n",
    "# Find index of these columns in X_train\n",
    "X_df = df.copy()\n",
    "X_df.drop(['Success'], axis=1, inplace=True)\n",
    "j = np.nonzero(X_df.columns==bin1)[0].item()\n",
    "k = np.nonzero(X_df.columns==bin2)[0].item()\n",
    "print(j, bin1)\n",
    "print(k, bin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001715747387314094\n",
      "0.003947456796958606\n"
     ]
    }
   ],
   "source": [
    "hj = 1 if xloc[0][j]==0 else -1\n",
    "hk = 1 if xloc[0][k]==0 else -1\n",
    "\n",
    "xloc_plus_hj = np.copy(xloc)\n",
    "xloc_plus_hj[0][j] += hj\n",
    "xloc_plus_hk = np.copy(xloc)\n",
    "xloc_plus_hk[0][k] += hk\n",
    "xloc_plus_hj_hk = np.copy(xloc_plus_hj)\n",
    "xloc_plus_hj_hk[0][k] += hk\n",
    "H_jk = (model.predict_proba(xloc_plus_hj_hk)[0,1]-\n",
    "                model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                model.predict_proba(xloc_plus_hk)[0,1]+\n",
    "                model.predict_proba(xloc)[0,1])/(hj*hk)\n",
    "# Off by factor of two\n",
    "print(H_jk)\n",
    "print(H[j,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both multilevel categorical\n",
    "No great way to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Marital\n",
      "0.0011670120874954352\n"
     ]
    }
   ],
   "source": [
    "# Identify two multilevel categorical variables in X_train/X_test/xloc \n",
    "cat1 = None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"multilevel\":\n",
    "        if cat1 is None:\n",
    "            cat1 = col\n",
    "        else:\n",
    "            cat2 = col\n",
    "            print(cat1, cat2)\n",
    "            break\n",
    "\n",
    "# Find the indices corresponding to them in X_df\n",
    "indices_of_col1 = np.nonzero(X_df.columns.str.startswith(cat1))[0]\n",
    "factor1 = xloc[0][indices_of_col1]\n",
    "level1 = np.argwhere(factor1==1).item()\n",
    "n_levels_j = len(indices_of_col1)\n",
    "\n",
    "indices_of_col2 = np.nonzero(X_df.columns.str.startswith(cat2))[0]\n",
    "factor2 = xloc[0][indices_of_col2]\n",
    "level2 = np.argwhere(factor2==1).item()\n",
    "n_levels_k = len(indices_of_col2)\n",
    "\n",
    "der_ests = []\n",
    "for a in range(n_levels_j):\n",
    "    if a != level1:\n",
    "        xloc_chg_j = np.copy(xloc)\n",
    "        chgd_factor_j = np.zeros(n_levels_j)\n",
    "        chgd_factor_j[a] = 1\n",
    "        xloc_chg_j[0][indices_of_col1] = chgd_factor_j\n",
    "\n",
    "        for b in range(n_levels_k):\n",
    "            if b != level2:\n",
    "                xloc_chg_k = np.copy(xloc)\n",
    "                chgd_factor_k = np.zeros(n_levels_k)\n",
    "                chgd_factor_k[b] = 1\n",
    "                xloc_chg_k[0][indices_of_col2] = chgd_factor_k\n",
    "\n",
    "                xloc_chg_jk = np.copy(xloc_chg_j)\n",
    "                xloc_chg_jk[0][indices_of_col2] = chgd_factor_k\n",
    "        \n",
    "                der_ests.append(model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                    model.predict_proba(xloc_chg_j)[0,1]-\n",
    "                    model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                    model.predict_proba(xloc)[0,1]) # Giles: always count change as 1\n",
    "H_jk = np.mean(der_ests)\n",
    "print(H_jk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003686542456068404\n"
     ]
    }
   ],
   "source": [
    "j = indices_of_col1[level1]\n",
    "k = indices_of_col2[level2]\n",
    "print(H[j,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H_{jk}$, both multilevel, new way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Marital\n"
     ]
    }
   ],
   "source": [
    "# Identify two multilevel categorical variables in X_train/X_test/xloc \n",
    "cat1 = None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"multilevel\":\n",
    "        if cat1 is None:\n",
    "            cat1 = col\n",
    "        else:\n",
    "            cat2 = col\n",
    "            print(cat1, cat2)\n",
    "            break\n",
    "\n",
    "# Find the indices corresponding to them in X_df\n",
    "indices_of_col1 = np.nonzero(X_df.columns.str.startswith(cat1))[0]\n",
    "factor1 = xloc[0][indices_of_col1]\n",
    "level1 = np.argwhere(factor1==1).item()\n",
    "n_levels_1 = len(indices_of_col1)\n",
    "\n",
    "indices_of_col2 = np.nonzero(X_df.columns.str.startswith(cat2))[0]\n",
    "factor2 = xloc[0][indices_of_col2]\n",
    "level2 = np.argwhere(factor2==1).item()\n",
    "n_levels_2 = len(indices_of_col2)\n",
    "\n",
    "H_multi_multi = np.zeros((n_levels_1, n_levels_2))\n",
    "for i in range(n_levels_1):\n",
    "    if i==level1:\n",
    "        H_multi_multi[i,:] = 0\n",
    "        continue\n",
    "    xloc_chg_1 = np.copy(xloc)\n",
    "    chgd_factor_1 = np.zeros(n_levels_1)\n",
    "    chgd_factor_1[i] = 1\n",
    "    xloc_chg_1[0][indices_of_col1] = chgd_factor_1\n",
    "    for j in range(n_levels_2):\n",
    "        if j==level2:\n",
    "            H_multi_multi[i,j] = 0\n",
    "            continue\n",
    "        xloc_chg_2 = np.copy(xloc)\n",
    "        chgd_factor_2 = np.zeros(n_levels_2)\n",
    "        chgd_factor_2[j] = 1\n",
    "        xloc_chg_2[0][indices_of_col2] = chgd_factor_2\n",
    "\n",
    "        xloc_chg_12 = np.copy(xloc_chg_2)\n",
    "        xloc_chg_12[0][indices_of_col2] = chgd_factor_2\n",
    "\n",
    "        H_multi_multi[i,j] = (model.predict_proba(xloc_chg_12)[0,1]-\n",
    "            model.predict_proba(xloc_chg_1)[0,1]-\n",
    "            model.predict_proba(xloc_chg_2)[0,1]+\n",
    "            model.predict_proba(xloc)[0,1]) # Giles: always count changes as 1\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4083634245365797\n",
      "0.9934238789821732\n",
      "0.9934238789821732\n",
      "[1.21323877 0.         4.88675536]\n"
     ]
    }
   ],
   "source": [
    "h1 = H_multi_multi\n",
    "h2 = H[:, indices_of_col2][indices_of_col1,:]\n",
    "# print(H_multi_multi.T)\n",
    "# print(H[:, indices_of_col2][indices_of_col1,:].T)\n",
    "print(np.corrcoef(h1.reshape(-1),h2.reshape(-1))[0,1])# Not super correlated...\n",
    "print(np.corrcoef(h1[:,0], h2[:,0])[0,1])# Very correlated\n",
    "print(np.corrcoef(h1[:,2], h2[:,2])[0,1]) # Same. I think this is because marital has 3 levels\n",
    "print(np.mean(h1/h2, axis=0)) # Close ish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01186381,  0.        , -0.01186381],\n",
       "       [ 0.01027155,  0.        ,  0.01027155],\n",
       "       [ 0.00361557,  0.        ,  0.00361557],\n",
       "       [ 0.00213855,  0.        ,  0.00213855],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [-0.03573835,  0.        , -0.03573835],\n",
       "       [ 0.00088328,  0.        ,  0.00088328],\n",
       "       [ 0.00532346,  0.        ,  0.00532346],\n",
       "       [-0.01595436,  0.        , -0.01595436],\n",
       "       [ 0.00414081,  0.        ,  0.00414081],\n",
       "       [-0.0017164 ,  0.        , -0.0017164 ],\n",
       "       [-0.00377911,  0.        , -0.00377911]])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00258725,  0.        ,  0.0049151 ],\n",
       "       [-0.00230898,  0.        , -0.00441021],\n",
       "       [-0.00080543,  0.        , -0.00153588],\n",
       "       [-0.00047544,  0.        , -0.00090629],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.00753789,  0.        ,  0.01423797],\n",
       "       [-0.00019603,  0.        , -0.00037357],\n",
       "       [-0.00118865,  0.        , -0.00226761],\n",
       "       [ 0.00345964,  0.        ,  0.00656592],\n",
       "       [-0.0009231 ,  0.        , -0.00176049],\n",
       "       [ 0.00037958,  0.        ,  0.00072288]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_hessian[10:21, 22:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Type\n",
    "### One Ordinal, One Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Age\n",
      "1 Default\n"
     ]
    }
   ],
   "source": [
    "ordinal_col, binary_col = None, None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"ordinal\" and ordinal_col is None:\n",
    "        ordinal_col = col\n",
    "    if types_dict[col]==\"binary\" and binary_col is None:\n",
    "        binary_col = col\n",
    "    if ordinal_col is not None and binary_col is not None:\n",
    "        break\n",
    "    \n",
    "# Find index of these columns\n",
    "j = np.nonzero(X_df.columns==ordinal_col)[0].item()\n",
    "k = np.nonzero(X_df.columns==binary_col)[0].item()\n",
    "print(j, ordinal_col)\n",
    "print(k, binary_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.071384572259921e-06\n",
      "1.4200479870196244e-05\n"
     ]
    }
   ],
   "source": [
    "hk = 1 if xloc[0][k]==0 else -1\n",
    "xloc_chg_k = np.copy(xloc)\n",
    "xloc_chg_k[0][k] += hk\n",
    "K = 1000\n",
    "n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "xj_vals = X_train[idx, j]\n",
    "values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "der_ests = []\n",
    "for i in range(len(values_j)):\n",
    "    hj = values_j[i] - xloc[0][j]\n",
    "    xloc_plus_hj = np.copy(xloc)\n",
    "    xloc_plus_hj[0][j] += hj\n",
    "    xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "    xloc_chg_jk[0][j] += hj\n",
    "    der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                    model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                    model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                    model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "H_jk = np.sum(der_ests * counts_j/K) # Weighted sum\n",
    "\n",
    "# Off by a factor of <2\n",
    "print(H_jk)\n",
    "print(H[j,k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Ordinal, One Multilevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Job\n"
     ]
    }
   ],
   "source": [
    "ordinal_col, multi_col = None, None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"ordinal\" and ordinal_col is None:\n",
    "        ordinal_col = col\n",
    "    if types_dict[col]==\"multilevel\" and multi_col is None:\n",
    "        multi_col = col\n",
    "    if ordinal_col is not None and multi_col is not None:\n",
    "        print(ordinal_col, multi_col)\n",
    "        break\n",
    "\n",
    "# Index of ordinal feature\n",
    "j = np.nonzero(X_df.columns==ordinal_col)[0].item()\n",
    "# Indices of multilevel feature (job)\n",
    "indices_of_col = np.nonzero(X_df.columns.str.startswith(multi_col))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 -8.00730105754372e-06\n",
      "1000 -8.00490823668195e-06\n",
      "100 -8.005302658967228e-06\n",
      "10 -8.005846689705539e-06\n"
     ]
    }
   ],
   "source": [
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_k = len(indices_of_col)\n",
    "hk = 1 # Always, according to Giles\n",
    "\n",
    "Ks = [10000, 1000, 100, 10]\n",
    "for K in Ks:\n",
    "    n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "    idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "    idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "    xj_vals = X_train[idx, j]\n",
    "    values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "    der_ests = []\n",
    "    for a in range(n_levels_k): # Change feature k st different feature on\n",
    "        if a != level:\n",
    "            xloc_chg_k = np.copy(xloc)\n",
    "            chgd_factor = np.zeros(n_levels_k)\n",
    "            chgd_factor[a] = 1\n",
    "            xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "            for b in range(len(values_j)): # Change feature j (ordinal)\n",
    "                hj = values_j[b] - xloc[0][j]\n",
    "                xloc_plus_hj = np.copy(xloc)\n",
    "                xloc_plus_hj[0][j] += hj\n",
    "                xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "                xloc_chg_jk[0][j] += hj\n",
    "                der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                                model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                                model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                                model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "    weights = np.tile(counts_j, n_levels_k-1) / (K*(n_levels_k-1))\n",
    "    H_jk = np.sum(der_ests * weights)\n",
    "    print(K, H_jk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.005846689705539e-06\n",
      "1.9363665482984658e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 0., 0., 2., 2., 2., 4., 8., 2.]),\n",
       " array([-7.44661119e-05, -6.47655650e-05, -5.50650181e-05, -4.53644711e-05,\n",
       "        -3.56639242e-05, -2.59633773e-05, -1.62628303e-05, -6.56228340e-06,\n",
       "         3.13826354e-06,  1.28388105e-05,  2.25393574e-05]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 14 # Index of level of that categorical feature\n",
    "print(H_jk)\n",
    "print(H[j,k])\n",
    "plt.hist(der_ests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_k = len(indices_of_col)\n",
    "hk = 1 # Always, according to Giles\n",
    "\n",
    "K = 1000\n",
    "H_ordinal_multi = np.zeros(n_levels_k)\n",
    "\n",
    "n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "xj_vals = X_train[idx, j]\n",
    "values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "\n",
    "for a in range(n_levels_k): # Change feature k st different feature on\n",
    "    if a == level:\n",
    "        H_ordinal_multi[a] = 0\n",
    "    if a != level:\n",
    "        der_ests = []\n",
    "        xloc_chg_k = np.copy(xloc)\n",
    "        chgd_factor = np.zeros(n_levels_k)\n",
    "        chgd_factor[a] = 1\n",
    "        xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "        for b in range(len(values_j)): # Change feature j (ordinal)\n",
    "            hj = values_j[b] - xloc[0][j]\n",
    "            xloc_plus_hj = np.copy(xloc)\n",
    "            xloc_plus_hj[0][j] += hj\n",
    "            xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "            xloc_chg_jk[0][j] += hj\n",
    "            der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                            model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                            model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "        weights = counts_j/K\n",
    "        H_ordinal_multi[a] = np.sum(der_ests * weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9951039544506997\n",
      "0.2498384291404371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fad5833a6d0>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h1 = H_ordinal_multi\n",
    "h2 = H[j, indices_of_col]\n",
    "# print(h1)\n",
    "# print(h2)\n",
    "print(np.corrcoef(h1.reshape(-1),h2.reshape(-1))[0,1])# Highly correlated\n",
    "print(np.mean(h1/h2)) # Close ish\n",
    "plt.scatter(h1.reshape(-1),h2.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One binary, one multilevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Job\n"
     ]
    }
   ],
   "source": [
    "binary_col, multi_col = None, None\n",
    "for col in df_orig.columns:\n",
    "    if types_dict[col]==\"binary\" and binary_col is None:\n",
    "        binary_col = col\n",
    "    if types_dict[col]==\"multilevel\" and multi_col is None:\n",
    "        multi_col = col\n",
    "    if binary_col is not None and multi_col is not None:\n",
    "        print(binary_col, multi_col)\n",
    "        break\n",
    "\n",
    "# Index of ordinal feature\n",
    "j = np.nonzero(X_df.columns==binary_col)[0].item()\n",
    "# Indices of multilevel feature (job)\n",
    "indices_of_col = np.nonzero(X_df.columns.str.startswith(multi_col))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0002723530380038461\n",
      "0.0006788893266817754\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hj = 1 if xloc[0][j]==0 else -1\n",
    "\n",
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_k = len(indices_of_col)\n",
    "hk = 1 # Always, according to Giles\n",
    "\n",
    "der_ests = []\n",
    "for a in range(n_levels_k): # Change feature k (multilevel) st different feature on\n",
    "    if a != level:\n",
    "        xloc_chg_k = np.copy(xloc)\n",
    "        chgd_factor = np.zeros(n_levels_k)\n",
    "        chgd_factor[a] = 1\n",
    "        xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "    \n",
    "        xloc_chg_j = np.copy(xloc)\n",
    "        xloc_chg_j[0][j] += hj\n",
    "        xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "        xloc_chg_jk[0][j] += hj\n",
    "        der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                        model.predict_proba(xloc_chg_j)[0,1]-\n",
    "                        model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                        model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "H_jk = np.mean(der_ests)\n",
    "print(H_jk)\n",
    "print(H[j,indices_of_col[level]])\n",
    "plt.hist(der_ests)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "hj = 1 if xloc[0][j]==0 else -1\n",
    "\n",
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels_k = len(indices_of_col)\n",
    "hk = 1 # Always, according to Giles\n",
    "\n",
    "H_binary_multi = np.zeros(n_levels_k)\n",
    "for a in range(n_levels_k): # Change feature k (multilevel) st different feature on\n",
    "    if a==level:\n",
    "        H_binary_multi[a] = 0\n",
    "    else:\n",
    "        xloc_chg_k = np.copy(xloc)\n",
    "        chgd_factor = np.zeros(n_levels_k)\n",
    "        chgd_factor[a] = 1\n",
    "        xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "    \n",
    "        xloc_chg_j = np.copy(xloc)\n",
    "        xloc_chg_j[0][j] += hj\n",
    "        xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "        xloc_chg_jk[0][j] += hj\n",
    "        H_binary_multi[a] = (model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                        model.predict_proba(xloc_chg_j)[0,1]-\n",
    "                        model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                        model.predict_proba(xloc)[0,1])/(hj*hk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949839259612031\n",
      "0.2418866836146455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fad404e67c0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h1 = H_binary_multi\n",
    "h2 = H[j, indices_of_col]\n",
    "# print(h1)\n",
    "# print(h2)\n",
    "print(np.corrcoef(h1.reshape(-1),h2.reshape(-1))[0,1])# Highly correlated\n",
    "print(np.mean(h1/h2)) # Close ish\n",
    "plt.scatter(h1.reshape(-1),h2.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# H_package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having looked at all possible pairs of features, it seems as though everything is off by a factor of at most two, except for perhaps the first and second derivates involving the multilevel categorical variables.\n",
    "\n",
    "## Compute gradient vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor each feature:\\n    check if it's ordinal, binary, or multilevel (in future datasets, may be continuous; this can be handled like ordinal)\\n    if ordinal or binary:\\n        get index for feature\\n    else:\\n        get all indices for feature\\n    if ordinal:\\n        Get K nearest values of feature, and count breakdown\\n        For each unique value of feature:\\n            Estimate derivative\\n        Take weighted sum, weighted by counts\\n    if binary:\\n        Take difference (feature on vs off)\\n    if multilevel:\\n        For all other possible levels:\\n            Compute difference if that level was on\\n        Take average\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for each feature:\n",
    "    check if it's ordinal, binary, or multilevel (in future datasets, may be continuous; this can be handled like ordinal)\n",
    "    if ordinal or binary:\n",
    "        get index for feature\n",
    "    else:\n",
    "        get all indices for feature\n",
    "    if ordinal:\n",
    "        Get K nearest values of feature, and count breakdown\n",
    "        For each unique value of feature:\n",
    "            Estimate derivative\n",
    "        Take weighted sum, weighted by counts\n",
    "    if binary:\n",
    "        Take difference (feature on vs off)\n",
    "    if multilevel:\n",
    "        For all other possible levels:\n",
    "            Compute difference if that level was on\n",
    "        Take average\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.09328114e-04],\n",
       "       [-7.33903519e-03],\n",
       "       [ 1.24393787e-06],\n",
       "       [-5.81891383e-02],\n",
       "       [-5.23785281e-02],\n",
       "       [-1.89344025e-04],\n",
       "       [ 3.50905882e-04],\n",
       "       [-8.21114795e-03],\n",
       "       [-1.12225428e-04],\n",
       "       [-2.40644790e-04],\n",
       "       [ 1.03222835e-02],\n",
       "       [-3.19016774e-02],\n",
       "       [-1.71559618e-02],\n",
       "       [-1.41712004e-02],\n",
       "       [-1.00074521e-02],\n",
       "       [ 4.18118869e-02],\n",
       "       [-1.17054393e-02],\n",
       "       [-2.07273456e-02],\n",
       "       [ 1.64609021e-02],\n",
       "       [-1.82401614e-02],\n",
       "       [-6.79085279e-03],\n",
       "       [-3.06132587e-03],\n",
       "       [-2.02788593e-02],\n",
       "       [-3.98528358e-02],\n",
       "       [-5.03464906e-03],\n",
       "       [-3.75065271e-02],\n",
       "       [-2.19094218e-02],\n",
       "       [ 2.05846163e-04],\n",
       "       [-5.95624135e-03],\n",
       "       [ 1.95350534e-02],\n",
       "       [ 9.20058332e-03],\n",
       "       [-9.39019809e-02],\n",
       "       [ 1.79722776e-02],\n",
       "       [-5.33972431e-02],\n",
       "       [ 1.20842872e-02],\n",
       "       [-1.28987592e-02],\n",
       "       [-3.47378824e-02],\n",
       "       [-5.97410701e-02],\n",
       "       [ 2.47626609e-03],\n",
       "       [ 5.66191697e-02],\n",
       "       [-2.76162569e-02],\n",
       "       [-5.92689266e-02],\n",
       "       [ 5.39417739e-02],\n",
       "       [ 3.94000196e-02],\n",
       "       [-6.89546093e-02],\n",
       "       [-2.48016966e-02],\n",
       "       [ 1.38065559e-01],\n",
       "       [-1.09475598e-01]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jeremygoldwasser/Desktop/SHAP/Code/bank_preprocess.ipynb Cell 64'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeremygoldwasser/Desktop/SHAP/Code/bank_preprocess.ipynb#ch0000100?line=0'>1</a>\u001b[0m X_train\u001b[39m.\u001b[39;49mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Age', 'Default', 'Balance', 'Housing', 'Loan', 'Day', 'Duration',\n",
       "       'Campaign', 'Prev_Days', 'Prev_Contacts', 'Job_admin.',\n",
       "       'Job_blue-collar', 'Job_entrepreneur', 'Job_housemaid',\n",
       "       'Job_management', 'Job_retired', 'Job_self-employed',\n",
       "       'Job_services', 'Job_student', 'Job_technician', 'Job_unemployed',\n",
       "       'Job_unknown', 'Marital_divorced', 'Marital_married',\n",
       "       'Marital_single', 'Education_primary', 'Education_secondary',\n",
       "       'Education_tertiary', 'Education_unknown', 'Contact_cellular',\n",
       "       'Contact_telephone', 'Contact_unknown', 'Month_apr', 'Month_aug',\n",
       "       'Month_dec', 'Month_feb', 'Month_jan', 'Month_jul', 'Month_jun',\n",
       "       'Month_mar', 'Month_may', 'Month_nov', 'Month_oct', 'Month_sep',\n",
       "       'Prev_Outcome_failure', 'Prev_Outcome_other',\n",
       "       'Prev_Outcome_success', 'Prev_Outcome_unknown'], dtype=object)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarized_feature_names = np.array(X_df.columns)\n",
    "binarized_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011863807005246162"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 10\n",
    "multilevel_feats = []\n",
    "for key, value in types_dict.items():\n",
    "    if value==\"multilevel\":\n",
    "        multilevel_feats.append(key)\n",
    "\n",
    "for feature in multilevel_feats:\n",
    "    if binarized_feature_names[j].startswith(feature):\n",
    "        break\n",
    "\n",
    "indices_of_col = np.nonzero(X_df.columns.str.startswith(feature))[0]\n",
    "factor = xloc[0][indices_of_col]\n",
    "level = np.argwhere(factor==1).item()\n",
    "n_levels = len(indices_of_col)\n",
    "if j==indices_of_col[level]:\n",
    "    derivative = 0\n",
    "else:\n",
    "    xloc_chg = np.copy(xloc)\n",
    "    xloc_chg[0][j] = 1\n",
    "    xloc_chg[0][indices_of_col[level]] = 0\n",
    "    # chgd_factor = np.zeros(n_levels)\n",
    "    # chgd_factor[] = 1\n",
    "    # xloc_chg[0][indices_of_col] = chgd_factor\n",
    "    derivative = model.predict_proba(xloc_chg)[0,1] - model.predict_proba(xloc)[0,1]\n",
    "\n",
    "    # xloc_chg = np.copy(xloc)\n",
    "    # chgd_factor = np.zeros(n_levels)\n",
    "    # chgd_factor[i] = 1\n",
    "    # xloc_chg[0][indices_of_col] = chgd_factor\n",
    "    # derivative = model.predict_proba(xloc_chg)[0,1] - model.predict_proba(xloc)[0,1]\n",
    "derivative\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01032228])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "est_gradient = []\n",
    "for j in range(d_binarized):\n",
    "    if np.isin(binarized_feature_names[j], feature_names):\n",
    "        # Not a multilevel feature\n",
    "        colname = binarized_feature_names[j]\n",
    "        type = types_dict[colname]\n",
    "        if type==\"ordinal\":\n",
    "            K = 1000\n",
    "            n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "            idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "\n",
    "            # Find indices of K rows of X whose j'th column is closest - but not zero - to xloc's.\n",
    "            idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "            xj_vals = X_train[idx, j]\n",
    "            values, counts = np.unique(xj_vals, return_counts=True)\n",
    "            der_ests = [0]*len(values)\n",
    "            for i in range(len(values)):\n",
    "                h = values[i] - xloc[0][j]\n",
    "                xloc_plus_h = np.copy(xloc)\n",
    "                xloc_plus_h[0][j] += h\n",
    "                der_ests[i] = (model.predict_proba(xloc_plus_h)[0,1] - model.predict_proba(xloc)[0,1])/h\n",
    "            derivative = np.sum(der_ests * counts/sum(counts)) # Weighted sum\n",
    "        elif type==\"binary\":\n",
    "            xloc_feature_on, xloc_feature_off = np.copy(xloc), np.copy(xloc)\n",
    "            xloc_feature_off[0][j] = 0\n",
    "            xloc_feature_on[0][j] = 1\n",
    "            derivative = model.predict_proba(xloc_feature_on)[0,1] - model.predict_proba(xloc_feature_off)[0,1]\n",
    "    else:# multilevel\n",
    "        for feature in multilevel_feats:\n",
    "            if binarized_feature_names[j].startswith(feature):\n",
    "                break\n",
    "\n",
    "        indices_of_col = np.nonzero(X_df.columns.str.startswith(feature))[0]\n",
    "        factor = xloc[0][indices_of_col]\n",
    "        level = np.argwhere(factor==1).item()\n",
    "        n_levels = len(indices_of_col)\n",
    "        if j==indices_of_col[level]:\n",
    "            derivative = 0\n",
    "        else:\n",
    "            xloc_chg = np.copy(xloc)\n",
    "            xloc_chg[0][j] = 1\n",
    "            xloc_chg[0][indices_of_col[level]] = 0\n",
    "            derivative = model.predict_proba(xloc_chg)[0,1] - model.predict_proba(xloc)[0,1]\n",
    "\n",
    "    est_gradient.append(derivative)\n",
    "    if verbose:\n",
    "        print(\"{}, {}\".format(colname, type))\n",
    "        print(derivative)\n",
    "        # Reality check this against true derivative.\n",
    "        print(gradient[j].item())    \n",
    "\n",
    "est_gradient = np.array(est_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordinal gradient ratios:\n",
      "0.9999987607453285\n",
      "binary gradient ratios:\n",
      "0.99970201901294\n",
      "multilevel gradient ratios:\n",
      "0.7354708769747983\n"
     ]
    }
   ],
   "source": [
    "# The estimated gradients for ordinal and binary features are all almost exactly half of the true values\n",
    "print('ordinal gradient ratios:')\n",
    "j_idx = []\n",
    "for j in range(d_binarized):\n",
    "    colname = binarized_feature_names[j]\n",
    "    if np.isin(colname, feature_names):\n",
    "        type = types_dict[colname]\n",
    "        if type==\"ordinal\":\n",
    "            j_idx.append(j)\n",
    "print(np.corrcoef(est_gradient[j_idx], gradient[j_idx].reshape(-1))[0,1])\n",
    "\n",
    "print('binary gradient ratios:')\n",
    "j_idx = []\n",
    "for j in range(d_binarized):\n",
    "    colname = binarized_feature_names[j]\n",
    "    if np.isin(colname, feature_names):\n",
    "        type = types_dict[colname]\n",
    "        if type==\"binary\":\n",
    "            j_idx.append(j)\n",
    "print(np.corrcoef(est_gradient[j_idx], gradient[j_idx].reshape(-1))[0,1])\n",
    "\n",
    "j_idx = []\n",
    "print('multilevel gradient ratios:')\n",
    "for j in range(d_binarized):\n",
    "    colname = binarized_feature_names[j]\n",
    "    if not np.isin(colname, feature_names):\n",
    "        # Multilevel\n",
    "        j_idx.append(j)\n",
    "print(np.corrcoef(est_gradient[j_idx], gradient[j_idx].reshape(-1))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK so the big gradient takeaways:\n",
    "- Calculated this way, the estimated gradients of ordinal and binary features are around half of what they really are\n",
    "- Extremely high correlation between gradients of ordinal & binary features\n",
    "- Old way, multilevel: Our estimated derivates always have the flipped sign. Their magnitude is less consistent.\n",
    "- New way, multilevel: Decent correlation, 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Hessian Matrix (new way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_second_deriv(colname, K=1000):\n",
    "    # Index in training dataset, which binarizes columns that are originally categorical with multiple levels\n",
    "    j = np.nonzero(X_df.columns==colname)[0].item() \n",
    "    n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "    idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "\n",
    "    # Find indices of K rows of X whose j'th features are closest - but not equal - to xloc's.\n",
    "    idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "    xj_vals = X_train[idx, j]\n",
    "    values, counts = np.unique(xj_vals, return_counts=True)\n",
    "    np.unique(xj_vals, return_counts=True)\n",
    "    second_der_ests = [0]*len(values)\n",
    "    for i in range(len(values)):\n",
    "        h = values[i] - xloc[0][j]\n",
    "        xloc_plus_h = np.copy(xloc)\n",
    "        xloc_plus_h[0][j] += h\n",
    "        xloc_minus_h = np.copy(xloc)\n",
    "        xloc_minus_h[0][j] -= h\n",
    "        second_der_ests[i] = (model.predict_proba(xloc_plus_h)[0,1] \n",
    "                        - 2*model.predict_proba(xloc)[0,1] \n",
    "                        + model.predict_proba(xloc_minus_h)[0,1])/(h**2)\n",
    "    second_derivative = np.sum(second_der_ests * counts/sum(counts)) # Weighted sum\n",
    "    return second_derivative\n",
    "\n",
    "\n",
    "\n",
    "def Hjk_ordinal_ordinal(colname_j, colname_k, K=1000):\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    n_equal_j = np.sum(X_train[:,j] == xloc[0,j])\n",
    "    n_equal_k = np.sum(X_train[:,k] == xloc[0,k])\n",
    "    idx_dists_ordered_j = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "    idx_dists_ordered_k = np.argsort(np.abs(X_train[:,k] - xloc[0,k]))\n",
    "\n",
    "    # Find indices of K rows of X whose j'th column is closest - but not zero - to xloc's.\n",
    "    idx_j = idx_dists_ordered_j[n_equal_j:(n_equal_j+K)]\n",
    "    idx_k = idx_dists_ordered_k[n_equal_k:(n_equal_k+K)]\n",
    "    xj_vals = X_train[idx_j, j]\n",
    "    xk_vals = X_train[idx_k, k]\n",
    "    values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "    values_k, counts_k = np.unique(xk_vals, return_counts=True)\n",
    "    n_unique_j = values_j.shape[0]\n",
    "    n_unique_k = values_k.shape[0]\n",
    "    der_ests = []\n",
    "    weights = []\n",
    "    for a in range(n_unique_j):\n",
    "        jval, nj = values_j[a], counts_j[a]\n",
    "        hj = jval - xloc[0][j]\n",
    "        xloc_plus_hj = np.copy(xloc)\n",
    "        xloc_plus_hj[0][j] += hj\n",
    "        \n",
    "        for b in range(n_unique_k):\n",
    "            kval, nk = values_k[b], counts_k[b]\n",
    "            hk = kval - xloc[0][k]\n",
    "            xloc_plus_hk = np.copy(xloc)\n",
    "            xloc_plus_hk[0][k] += hk\n",
    "            xloc_plus_hj_hk = np.copy(xloc_plus_hj)\n",
    "            xloc_plus_hj_hk[0][k] += hk\n",
    "            der_ests.append((model.predict_proba(xloc_plus_hj_hk)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hk)[0,1]+\n",
    "                            model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "            weights.append((nj*nk)/(K**2))\n",
    "    H_jk = np.sum(der_ests * np.array(weights)) # Weighted sum\n",
    "    return H_jk\n",
    "    \n",
    "\n",
    "def Hjk_binary_binary(colname_j, colname_k):\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    hj = 1 if xloc[0][j]==0 else -1\n",
    "    hk = 1 if xloc[0][k]==0 else -1\n",
    "\n",
    "    xloc_plus_hj = np.copy(xloc)\n",
    "    xloc_plus_hj[0][j] += hj\n",
    "    xloc_plus_hk = np.copy(xloc)\n",
    "    xloc_plus_hk[0][k] += hk\n",
    "    xloc_plus_hj_hk = np.copy(xloc_plus_hj)\n",
    "    xloc_plus_hj_hk[0][k] += hk\n",
    "    H_jk = (model.predict_proba(xloc_plus_hj_hk)[0,1]-\n",
    "                    model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                    model.predict_proba(xloc_plus_hk)[0,1]+\n",
    "                    model.predict_proba(xloc)[0,1])/(hj*hk)\n",
    "    return H_jk\n",
    "\n",
    "\n",
    "def Hjk_ordinal_binary(colname_j, colname_k, K=1000, verbose=False):\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    hk = 1 if xloc[0][k]==0 else -1\n",
    "    xloc_chg_k = np.copy(xloc)\n",
    "    xloc_chg_k[0][k] += hk\n",
    "    K = 1000\n",
    "    n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "    idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "    idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "    xj_vals = X_train[idx, j]\n",
    "    values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "    der_ests = []\n",
    "    for i in range(len(values_j)):\n",
    "        hj = values_j[i] - xloc[0][j]\n",
    "        xloc_plus_hj = np.copy(xloc)\n",
    "        xloc_plus_hj[0][j] += hj\n",
    "        xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "        xloc_chg_jk[0][j] += hj\n",
    "        der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                        model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                        model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                        model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "    H_jk = np.sum(der_ests * counts_j/K) # Weighted sum\n",
    "    return H_jk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hjk_multi_multi(colname_j, colname_k, flip_sign=False):\n",
    "    # Find the indices corresponding to these columns in X_df\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    multilevel_feats = get_multilevel_features()\n",
    "    for feature_j in multilevel_feats:\n",
    "        if colname_j.startswith(feature_j):\n",
    "            break\n",
    "    indices_of_col1 = np.nonzero(X_df.columns.str.startswith(feature_j))[0]\n",
    "    factor1 = xloc[0][indices_of_col1]\n",
    "    level1 = np.argwhere(factor1==1).item()\n",
    "    \n",
    "\n",
    "    for feature_k in multilevel_feats:\n",
    "        if colname_k.startswith(feature_k):\n",
    "            break\n",
    "    indices_of_col2 = np.nonzero(X_df.columns.str.startswith(feature_k))[0]\n",
    "    factor2 = xloc[0][indices_of_col2]\n",
    "    level2 = np.argwhere(factor2==1).item()\n",
    "\n",
    "    if np.array_equal(indices_of_col1, indices_of_col2):\n",
    "        # Same feature - 2 levels can't be on\n",
    "        H_jk = 0\n",
    "    elif j==indices_of_col1[level1] or k==indices_of_col2[level2]:\n",
    "        # Either feature in question is already on\n",
    "        H_jk = 0\n",
    "    else:\n",
    "        # Both different\n",
    "        xloc_chg_1 = np.copy(xloc)\n",
    "        xloc_chg_1[0][j] = 1\n",
    "        xloc_chg_1[0][indices_of_col1[level1]] = 0\n",
    "\n",
    "        xloc_chg_2 = np.copy(xloc)\n",
    "        xloc_chg_2[0][k] = 1\n",
    "        xloc_chg_2[0][indices_of_col2[level2]] = 0\n",
    "\n",
    "        xloc_chg_12 = np.copy(xloc_chg_2)\n",
    "        xloc_chg_12[0][j] = 1\n",
    "        xloc_chg_12[0][indices_of_col1[level1]] = 0\n",
    "\n",
    "        H_jk = (model.predict_proba(xloc_chg_12)[0,1]-\n",
    "            model.predict_proba(xloc_chg_1)[0,1]-\n",
    "            model.predict_proba(xloc_chg_2)[0,1]+\n",
    "            model.predict_proba(xloc)[0,1]) # Giles: always count changes as 1\n",
    "        if flip_sign:\n",
    "            H_jk *= -1\n",
    "    return H_jk\n",
    "    \n",
    "\n",
    "def Hjk_ordinal_multilevel(colname_j, colname_k, K = 1000):\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    multilevel_feats = get_multilevel_features()\n",
    "    for feature_k in multilevel_feats:\n",
    "        if colname_k.startswith(feature_k):\n",
    "            break\n",
    "    indices_of_col_k = np.nonzero(X_df.columns.str.startswith(feature_k))[0]\n",
    "    factor = xloc[0][indices_of_col_k]\n",
    "    level = np.argwhere(factor==1).item()\n",
    "    if k==indices_of_col_k[level]:\n",
    "        H_jk = 0\n",
    "    else:\n",
    "        hk = 1\n",
    "        # Get adjacent values of ordinal feature (j) and their relative frequencies\n",
    "        n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "        idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "        idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "        xj_vals = X_train[idx, j]\n",
    "        values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "        weights = counts_j/K\n",
    "\n",
    "        # Change feature k (column of multilevel feature)\n",
    "        xloc_chg_k = np.copy(xloc)\n",
    "        xloc_chg_k[0,k] = 1\n",
    "        xloc_chg_k[0,indices_of_col_k[level]] = 0\n",
    "        der_ests = []\n",
    "        for b in range(len(values_j)): # Change feature j (ordinal)\n",
    "            hj = values_j[b] - xloc[0][j]\n",
    "            xloc_plus_hj = np.copy(xloc)\n",
    "            xloc_plus_hj[0][j] += hj\n",
    "            xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "            xloc_chg_jk[0][j] += hj\n",
    "            der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                            model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "                            model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                            model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "        \n",
    "        H_jk = np.sum(der_ests * weights)\n",
    "    return H_jk\n",
    "\n",
    "def Hjk_binary_multilevel(colname_j, colname_k):\n",
    "    j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "    k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "    multilevel_feats = get_multilevel_features()\n",
    "    for feature_k in multilevel_feats:\n",
    "        if colname_k.startswith(feature_k):\n",
    "            break\n",
    "    indices_of_col_k = np.nonzero(X_df.columns.str.startswith(feature_k))[0]\n",
    "    factor = xloc[0][indices_of_col_k]\n",
    "    level = np.argwhere(factor==1).item()\n",
    "    if k==indices_of_col_k[level]:\n",
    "        H_jk = 0\n",
    "    else:\n",
    "        # Change feature k (column of multilevel feature)\n",
    "        xloc_chg_k = np.copy(xloc)\n",
    "        xloc_chg_k[0,k] = 1\n",
    "        xloc_chg_k[0,indices_of_col_k[level]] = 0\n",
    "\n",
    "        hj = 1 if xloc[0][j]==0 else -1\n",
    "        xloc_chg_j = np.copy(xloc)\n",
    "        xloc_chg_j[0,j] += hj\n",
    "\n",
    "        xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "        xloc_chg_jk[0,j] += hj\n",
    "\n",
    "        H_jk = (model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "                            model.predict_proba(xloc_chg_j)[0,1]-\n",
    "                            model.predict_proba(xloc_chg_k)[0,1]+\n",
    "                            model.predict_proba(xloc)[0,1])\n",
    "    return H_jk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hessian = np.zeros((d_binarized,d_binarized))\n",
    "for j in range(d_binarized):\n",
    "    colname_j = binarized_feature_names[j]\n",
    "    for k in range(j+1):\n",
    "        if j==k:\n",
    "            # Take second derivative\n",
    "            if np.isin(colname_j, feature_names):\n",
    "                # Feature is binary or ordinal, not multilevel\n",
    "                type = types_dict[colname_j]\n",
    "                if type==\"ordinal\":\n",
    "                    est_hessian[j, j] = ordinal_second_deriv(colname_j)\n",
    "            else:\n",
    "                # Multilevel or ordinal\n",
    "                est_hessian[j, j] = 0\n",
    "        else:\n",
    "            colname_k = binarized_feature_names[k]\n",
    "            type_j = types_dict[colname_j] if np.isin(colname_j, feature_names) else \"multilevel\"\n",
    "            type_k = types_dict[colname_k] if np.isin(colname_k, feature_names) else \"multilevel\"\n",
    "            # Both same type\n",
    "            if type_j==\"ordinal\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_ordinal(colname_j, colname_k)\n",
    "            elif type_j==\"binary\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_binary_binary(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_multi_multi(colname_j, colname_k)\n",
    "                \n",
    "            # # Of different types\n",
    "            # # <ordinal, binary>.\n",
    "            if type_j==\"ordinal\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_ordinal_binary(colname_j, colname_k)\n",
    "            elif type_j==\"binary\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_binary(colname_k, colname_j)\n",
    "            \n",
    "            # <ordinal, multilevel>. \n",
    "            if type_j==\"ordinal\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_ordinal_multilevel(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_multilevel(colname_k, colname_j)\n",
    "\n",
    "            # <binary, multilevel>. TO DO\n",
    "            if type_j==\"binary\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_binary_multilevel(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_binary_multilevel(colname_k, colname_j)\n",
    "            \n",
    "            est_hessian[j, k] = H_jk\n",
    "            est_hessian[k, j] = H_jk\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99548519]\n",
      " [0.99548519 1.        ]]\n",
      "[[1.         0.99537415]\n",
      " [0.99537415 1.        ]]\n",
      "[[1.         0.33719426]\n",
      " [0.33719426 1.        ]]\n",
      "[[ 1.         -0.32603734]\n",
      " [-0.32603734  1.        ]]\n",
      "[[ 1.         -0.99581582]\n",
      " [-0.99581582  1.        ]]\n",
      "[[ 1.         -0.99611058]\n",
      " [-0.99611058  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Extremely high correlation for ordinal, multi and binary, multi pairings\n",
    "print(np.corrcoef(est_hessian[0, 10:21].reshape(-1), H[0, 10:21].reshape(-1)))# ordinal, multi\n",
    "print(np.corrcoef(est_hessian[1, 10:21].reshape(-1), H[1, 10:21].reshape(-1)))# binary, multi\n",
    "print(np.corrcoef(H.reshape(-1), est_hessian.reshape(-1)))# Overall relatively low correlationâ€¦\n",
    "\n",
    "print(np.corrcoef(est_hessian[10:21, 22:25].reshape(-1), H[10:21, 22:25].reshape(-1)))# multi, another multi. BAD, flipped\n",
    "print(np.corrcoef(est_hessian[10:21, 22].reshape(-1), H[10:21, 22].reshape(-1)))# multi, another multi. Flipped. weirdâ€¦\n",
    "print(np.corrcoef(est_hessian[10:21, 24].reshape(-1), H[10:21, 24].reshape(-1)))# multi, another multi. Flipped. weirdâ€¦\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat but flip sign for hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_hessian_flipped = np.zeros((d_binarized,d_binarized))\n",
    "for j in range(d_binarized):\n",
    "    colname_j = binarized_feature_names[j]\n",
    "    for k in range(j+1):\n",
    "        if j==k:\n",
    "            # Take second derivative\n",
    "            if np.isin(colname_j, feature_names):\n",
    "                # Feature is binary or ordinal, not multilevel\n",
    "                type = types_dict[colname_j]\n",
    "                if type==\"ordinal\":\n",
    "                    est_hessian_flipped[j, j] = ordinal_second_deriv(colname_j)\n",
    "            else:\n",
    "                # Multilevel or ordinal\n",
    "                est_hessian_flipped[j, j] = 0\n",
    "        else:\n",
    "            colname_k = binarized_feature_names[k]\n",
    "            type_j = types_dict[colname_j] if np.isin(colname_j, feature_names) else \"multilevel\"\n",
    "            type_k = types_dict[colname_k] if np.isin(colname_k, feature_names) else \"multilevel\"\n",
    "            # Both same type\n",
    "            if type_j==\"ordinal\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_ordinal(colname_j, colname_k)\n",
    "            elif type_j==\"binary\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_binary_binary(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_multi_multi(colname_j, colname_k, flip_sign=True)\n",
    "                \n",
    "            # # Of different types\n",
    "            # # <ordinal, binary>.\n",
    "            if type_j==\"ordinal\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_ordinal_binary(colname_j, colname_k)\n",
    "            elif type_j==\"binary\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_binary(colname_k, colname_j)\n",
    "            \n",
    "            # <ordinal, multilevel>. \n",
    "            if type_j==\"ordinal\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_ordinal_multilevel(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"ordinal\":\n",
    "                H_jk = Hjk_ordinal_multilevel(colname_k, colname_j)\n",
    "\n",
    "            # <binary, multilevel>. TO DO\n",
    "            if type_j==\"binary\" and type_k==\"multilevel\":\n",
    "                H_jk = Hjk_binary_multilevel(colname_j, colname_k)\n",
    "            elif type_j==\"multilevel\" and type_k==\"binary\":\n",
    "                H_jk = Hjk_binary_multilevel(colname_k, colname_j)\n",
    "            \n",
    "            est_hessian_flipped[j, k] = H_jk\n",
    "            est_hessian_flipped[k, j] = H_jk\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99548519]\n",
      " [0.99548519 1.        ]]\n",
      "[[1.         0.99537415]\n",
      " [0.99537415 1.        ]]\n",
      "[[ 1.         -0.17479691]\n",
      " [-0.17479691  1.        ]]\n",
      "[[1.         0.32603734]\n",
      " [0.32603734 1.        ]]\n",
      "[[1.         0.99581582]\n",
      " [0.99581582 1.        ]]\n",
      "[[1.         0.99611058]\n",
      " [0.99611058 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Extremely high correlation for ordinal, multi and binary, multi pairings\n",
    "print(np.corrcoef(est_hessian_flipped[0, 10:21].reshape(-1), H[0, 10:21].reshape(-1)))# ordinal, multi\n",
    "print(np.corrcoef(est_hessian_flipped[1, 10:21].reshape(-1), H[1, 10:21].reshape(-1)))# binary, multi\n",
    "print(np.corrcoef(H.reshape(-1), est_hessian_flipped.reshape(-1)))# Overall relatively low correlationâ€¦\n",
    "\n",
    "print(np.corrcoef(est_hessian_flipped[10:21, 22:25].reshape(-1), H[10:21, 22:25].reshape(-1)))# multi, another multi. BAD, flipped\n",
    "print(np.corrcoef(est_hessian_flipped[10:21, 22].reshape(-1), H[10:21, 22].reshape(-1)))# multi, another multi. Flipped. weirdâ€¦\n",
    "print(np.corrcoef(est_hessian_flipped[10:21, 24].reshape(-1), H[10:21, 24].reshape(-1)))# multi, another multi. Flipped. weirdâ€¦\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so the big takeaways:\n",
    "Second derivatives\n",
    "- The second derivatives of ordinal features - both wrt the same variable and different ones - are consistently around half of the true values. Strangely, the ratio hovers almost exactly around 0.58.\n",
    "- Binary variables are calculated to actually have a second derivative (permitting infinitesimal change).\n",
    "- The second derivative of multilevel features are of the right sign. Their magnitude can be way off, though.\n",
    "\n",
    "Hessian off-diagonals\n",
    "- When one feature is ordinal and the other is binary, the estimated Hessian is around half of the true value.\n",
    "- When one feature is categorical with >2 levels and the other isn't (either binary or ordinal), the estimated hessian has the opposite sign. (That is, if we compare this to the Hessian of the binarized data.) The magnitudes are all over the place, but might be (negative) half on average with some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = \"/Users/jeremygoldwasser/Desktop/SHAP/Data/bank\"\n",
    "from os.path import join\n",
    "np.save(join(dirpath, \"gradient.npy\"), est_gradient)\n",
    "np.save(join(dirpath, \"hessian.npy\"), est_hessian)\n",
    "np.save(join(dirpath, \"hessian_flipped.npy\"), est_hessian_flipped)\n",
    "np.save(join(dirpath, \"X_train.npy\"), X_train)\n",
    "np.save(join(dirpath, \"X_val.npy\"), X_val)\n",
    "np.save(join(dirpath, \"X_test.npy\"), X_test)\n",
    "np.save(join(dirpath, \"Y_train.npy\"), Y_train)\n",
    "np.save(join(dirpath, \"Y_val.npy\"), Y_val)\n",
    "np.save(join(dirpath, \"Y_test.npy\"), Y_test)\n",
    "X_df.to_csv(join(dirpath, \"X_df.csv\"), index=False)\n",
    "df_orig.to_csv(join(dirpath, \"df_orig.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'logreg_model.sav'\n",
    "pickle.dump(model, open(join(dirpath, filename), 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Hessian Matrix (old way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def old_Hjk_multi_multi(colname_j, colname_k, verbose=False):\n",
    "#     # Find the indices corresponding to them in X_df\n",
    "#     indices_of_col_j = np.nonzero(X_df.columns.str.startswith(colname_j))[0]\n",
    "#     factor_j = xloc[0][indices_of_col_j]\n",
    "#     level_j = np.argwhere(factor_j==1).item()\n",
    "#     n_levels_j = len(indices_of_col_j)\n",
    "\n",
    "#     indices_of_col_k = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "#     factor_k = xloc[0][indices_of_col_k]\n",
    "#     level_k = np.argwhere(factor_k==1).item()\n",
    "#     n_levels_k = len(indices_of_col_k)\n",
    "\n",
    "#     der_ests = []\n",
    "#     for a in range(n_levels_j):\n",
    "#         if a != level_j:\n",
    "#             xloc_chg_j = np.copy(xloc)\n",
    "#             chgd_factor_j = np.zeros(n_levels_j)\n",
    "#             chgd_factor_j[a] = 1\n",
    "#             xloc_chg_j[0][indices_of_col_j] = chgd_factor_j\n",
    "\n",
    "#             for b in range(n_levels_k):\n",
    "#                 if b != level_k:\n",
    "#                     xloc_chg_k = np.copy(xloc)\n",
    "#                     chgd_factor_k = np.zeros(n_levels_k)\n",
    "#                     chgd_factor_k[b] = 1\n",
    "#                     xloc_chg_k[0][indices_of_col_k] = chgd_factor_k\n",
    "\n",
    "#                     xloc_chg_jk = np.copy(xloc_chg_j)\n",
    "#                     xloc_chg_jk[0][indices_of_col_k] = chgd_factor_k\n",
    "            \n",
    "#                     der_ests.append(model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "#                         model.predict_proba(xloc_chg_j)[0,1]-\n",
    "#                         model.predict_proba(xloc_chg_k)[0,1]+\n",
    "#                         model.predict_proba(xloc)[0,1]) # Giles: always count change as 1\n",
    "#     H_jk = np.mean(der_ests)\n",
    "#     if verbose:\n",
    "#         print(colname_j, colname_k)\n",
    "#         j, k = indices_of_col_j[level_j], indices_of_col_k[level_k]\n",
    "#         print(\"True: {}\".format(H[j,k]))\n",
    "#         print(\"Est: {}\".format(H_jk))\n",
    "#     return H_jk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def old_Hjk_ordinal_multilevel(colname_j, colname_k, K=1000, verbose=False):\n",
    "#     j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "#     indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "#     # Get information about categorical feature\n",
    "#     factor = xloc[0][indices_of_col]\n",
    "#     level = np.argwhere(factor==1).item()\n",
    "#     n_levels_k = len(indices_of_col)\n",
    "#     hk = 1\n",
    "\n",
    "#     # Find nearby values of ordinal feature\n",
    "#     n_equal = np.sum(X_train[:,j] == xloc[0,j])\n",
    "#     idx_dists_ordered = np.argsort(np.abs(X_train[:,j] - xloc[0,j]))\n",
    "#     idx = idx_dists_ordered[n_equal:(n_equal+K)]\n",
    "#     xj_vals = X_train[idx, j]\n",
    "#     values_j, counts_j = np.unique(xj_vals, return_counts=True)\n",
    "#     der_ests = []\n",
    "#     for a in range(n_levels_k): # Change feature k st a different feature is on\n",
    "#         if a != level:\n",
    "#             xloc_chg_k = np.copy(xloc)\n",
    "#             chgd_factor = np.zeros(n_levels_k)\n",
    "#             chgd_factor[a] = 1\n",
    "#             xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "#             for b in range(len(values_j)): # Change feature j (ordinal)\n",
    "#                 hj = values_j[b] - xloc[0][j]\n",
    "#                 xloc_plus_hj = np.copy(xloc)\n",
    "#                 xloc_plus_hj[0][j] += hj\n",
    "#                 xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "#                 xloc_chg_jk[0][j] += hj\n",
    "#                 der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "#                                 model.predict_proba(xloc_plus_hj)[0,1]-\n",
    "#                                 model.predict_proba(xloc_chg_k)[0,1]+\n",
    "#                                 model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "#     weights = np.tile(counts_j, n_levels_k-1) / (K*(n_levels_k-1))\n",
    "#     H_jk = np.sum(der_ests * weights)\n",
    "#     if verbose:\n",
    "#         print(colname_j, colname_k)\n",
    "#         print(\"True: {}\".format(H[j,k]))\n",
    "#         print(\"Est: {}\".format(H_jk))\n",
    "#     return H_jk\n",
    "\n",
    "    \n",
    "\n",
    "# def old_Hjk_binary_multilevel(colname_j, colname_k, verbose=False):\n",
    "#     j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "#     indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "\n",
    "#     hj = 1 if xloc[0][j]==0 else -1\n",
    "#     # Get information about categorical variable\n",
    "#     factor = xloc[0][indices_of_col]\n",
    "#     level = np.argwhere(factor==1).item()\n",
    "#     n_levels_k = len(indices_of_col)\n",
    "#     hk = 1 # Always, according to Giles\n",
    "\n",
    "#     der_ests = []\n",
    "#     for a in range(n_levels_k): # Change feature k (multilevel) st different feature on\n",
    "#         if a != level:\n",
    "#             xloc_chg_k = np.copy(xloc)\n",
    "#             chgd_factor = np.zeros(n_levels_k)\n",
    "#             chgd_factor[a] = 1\n",
    "#             xloc_chg_k[0][indices_of_col] = chgd_factor\n",
    "        \n",
    "#             xloc_chg_j = np.copy(xloc)\n",
    "#             xloc_chg_j[0][j] += hj\n",
    "#             xloc_chg_jk = np.copy(xloc_chg_k)\n",
    "#             xloc_chg_jk[0][j] += hj\n",
    "#             der_ests.append((model.predict_proba(xloc_chg_jk)[0,1]-\n",
    "#                             model.predict_proba(xloc_chg_j)[0,1]-\n",
    "#                             model.predict_proba(xloc_chg_k)[0,1]+\n",
    "#                             model.predict_proba(xloc)[0,1])/(hj*hk))\n",
    "#     H_jk = np.mean(der_ests)\n",
    "#     if verbose:\n",
    "#         print(colname_j, colname_k)\n",
    "#         print(\"True: {}\".format(H[j,indices_of_col[level]]))\n",
    "#         print(\"Est: {}\".format(H_jk))\n",
    "#     return H_jk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_hessian = np.zeros((d_orig, d_orig))\n",
    "# K = 1000\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig+1): # Symmetric\n",
    "#         if j_orig==k_orig:\n",
    "#             # Take second derivative\n",
    "#             colname = feature_names[j_orig]\n",
    "#             type = types_dict[colname]\n",
    "#             if type==\"binary\" or type==\"multilevel\":\n",
    "#                 est_hessian[j_orig, j_orig] = 0\n",
    "#             else:# Ordinal\n",
    "#                 second_derivative = ordinal_second_deriv(colname)\n",
    "#                 est_hessian[j_orig, j_orig] = second_derivative\n",
    "#         else:\n",
    "#             colname_j = feature_names[j_orig]\n",
    "#             type_j = types_dict[colname_j]\n",
    "#             colname_k = feature_names[k_orig]\n",
    "#             type_k = types_dict[colname_k]\n",
    "\n",
    "#             # Both the same type\n",
    "#             if type_j==\"ordinal\" and type_k==\"ordinal\":\n",
    "#                 # So far so good. Close to half\n",
    "#                 H_jk = Hjk_ordinal_ordinal(colname_j, colname_k)\n",
    "#             elif type_j==\"binary\" and type_k==\"binary\":\n",
    "#                 H_jk = Hjk_binary_binary(colname_j, colname_k) # So far so good. Definitely close to half\n",
    "#             elif type_j==\"multilevel\" and type_k==\"multilevel\":\n",
    "#                 H_jk = Hjk_multi_multi(colname_j, colname_k) # Not too far off...\n",
    "                \n",
    "#             # Of different types\n",
    "#             # <ordinal, binary>. Definitely close to half\n",
    "#             if type_j==\"ordinal\" and type_k==\"binary\":\n",
    "#                 H_jk = Hjk_ordinal_binary(colname_j, colname_k)\n",
    "#             elif type_j==\"binary\" and type_k==\"ordinal\":\n",
    "#                 H_jk = Hjk_ordinal_binary(colname_k, colname_j)\n",
    "            \n",
    "#             # <ordinal, multilevel>. Often relatively close but sign usually flipped\n",
    "#             if type_j==\"ordinal\" and type_k==\"multilevel\":\n",
    "#                 H_jk = Hjk_ordinal_multilevel(colname_j, colname_k)\n",
    "#             elif type_j==\"multilevel\" and type_k==\"ordinal\":\n",
    "#                 H_jk = Hjk_ordinal_multilevel(colname_k, colname_j)\n",
    "\n",
    "#             # <binary, multilevel>. less correlated but somewhat, & sign usually flipped\n",
    "#             if type_j==\"binary\" and type_k==\"multilevel\":\n",
    "#                 H_jk = Hjk_binary_multilevel(colname_j, colname_k)\n",
    "#             elif type_j==\"multilevel\" and type_k==\"binary\":\n",
    "#                 H_jk = Hjk_binary_multilevel(colname_k, colname_j)\n",
    "            \n",
    "#             est_hessian[j_orig, k_orig] = H_jk\n",
    "#             est_hessian[k_orig, j_orig] = H_jk\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The estimated hessians for ordinal and binary features\n",
    "# print('ordinal second derivative ratios:')# Again, all almost exactly half of the true values\n",
    "# for j_orig in range(d_orig):\n",
    "#     colname = feature_names[j_orig]\n",
    "#     type = types_dict[colname]\n",
    "#     if type == \"ordinal\":\n",
    "#         j = np.nonzero(X_df.columns==colname)[0].item()\n",
    "#         print(np.round(est_hessian[j_orig, j_orig]/H[j,j].item(), 8)) # Conspicuously close to one another...\n",
    "\n",
    "# print('True binary second derivatives:')\n",
    "# for j_orig in range(d_orig):\n",
    "#     colname = feature_names[j_orig]\n",
    "#     type = types_dict[colname]\n",
    "#     if type == \"binary\":\n",
    "#         j = np.nonzero(X_df.columns==colname)[0].item()\n",
    "#         print(H[j,j].item())\n",
    "\n",
    "# print('True multilevel second derivatives:')\n",
    "# for j_orig in range(d_orig):\n",
    "#     colname = feature_names[j_orig]\n",
    "#     type = types_dict[colname]\n",
    "#     if type == \"multilevel\":\n",
    "#         indices_of_col = np.nonzero(X_df.columns.str.startswith(colname))[0]\n",
    "#         factor = xloc[0][indices_of_col]\n",
    "#         level = np.argwhere(factor==1).item()\n",
    "#         print(np.round(gradient[indices_of_col[level]].item(), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ordinal-ordinal ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"ordinal\" and type_k==\"ordinal\":\n",
    "#             j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "#             k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # binary ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"binary\" and type_k==\"binary\":\n",
    "#             j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "#             k = np.nonzero(X_df.columns==colname_k)[0].item()\n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multilevel ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"multilevel\" and type_k==\"multilevel\":\n",
    "#             indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_j))[0]\n",
    "#             factor = xloc[0][indices_of_col]\n",
    "#             level = np.argwhere(factor==1).item()\n",
    "#             j = indices_of_col[level]\n",
    "\n",
    "#             indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "#             factor = xloc[0][indices_of_col]\n",
    "#             level = np.argwhere(factor==1).item()\n",
    "#             k = indices_of_col[level]\n",
    "            \n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (ordinal,binary) ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"ordinal\" and type_k==\"binary\":\n",
    "#             j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "#             k = np.nonzero(X_df.columns==colname_k)[0].item()            \n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (ordinal,multilevel) ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"ordinal\" and type_k==\"multilevel\":\n",
    "#             j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "\n",
    "#             indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "#             factor = xloc[0][indices_of_col]\n",
    "#             level = np.argwhere(factor==1).item()\n",
    "#             k = indices_of_col[level]\n",
    "            \n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (binary,multilevel) ratio\n",
    "# for j_orig in range(d_orig):\n",
    "#     for k_orig in range(j_orig):\n",
    "#         colname_j = feature_names[j_orig]\n",
    "#         type_j = types_dict[colname_j]\n",
    "#         colname_k = feature_names[k_orig]\n",
    "#         type_k = types_dict[colname_k]\n",
    "#         # Both ordinal\n",
    "#         if type_j==\"binary\" and type_k==\"multilevel\":\n",
    "#             j = np.nonzero(X_df.columns==colname_j)[0].item()\n",
    "\n",
    "#             indices_of_col = np.nonzero(X_df.columns.str.startswith(colname_k))[0]\n",
    "#             factor = xloc[0][indices_of_col]\n",
    "#             level = np.argwhere(factor==1).item()\n",
    "#             k = indices_of_col[level]\n",
    "            \n",
    "#             print(est_hessian[j_orig, k_orig]/H[j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
