{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap # The original SHAP package contains the dataset\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from helper import *\n",
    "# from helper_dep import *\n",
    "# from helper_indep import *\n",
    "# from helper_shapley_sampling import *\n",
    "# from helper_kshap import *\n",
    "import sys\n",
    "sys.path.append('../GilesCode/')\n",
    "from helper2 import *\n",
    "from helper2_dep import *\n",
    "from helper2_indep import *\n",
    "from helper2_shapley_sampling import *\n",
    "from helper4_kshap import *\n",
    "import matplotlib.pyplot as plt\n",
    "import sage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "German Credit dataset has 1000 samples, 20 covariates; response is \"good customer\" (binary); ~70% of Ys are 1. On UCI ML Repo.\n",
    "\n",
    "Problem: can't load as already categorical. The Gradient Boosting model they used allowed you to just input the (numerical) data w/ a list of the categorical indices -- we can't do that with sklrean logistic regression.\n",
    "- FWIW, I think we had to convert things manually for the bank dataset. I just don't want to have to deal with that again.\n",
    "- Actually, it might have been OK to begin with - I just made things more complicated than necessary. Wouldn't be the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checking Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit History</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Credit Amount</th>\n",
       "      <th>Savings Account/Bonds</th>\n",
       "      <th>Employment Since</th>\n",
       "      <th>Installment Rate</th>\n",
       "      <th>Personal Status</th>\n",
       "      <th>Debtors/Guarantors</th>\n",
       "      <th>...</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Other Installment Plans</th>\n",
       "      <th>Housing Ownership</th>\n",
       "      <th>Number Existing Credits</th>\n",
       "      <th>Job</th>\n",
       "      <th>Number Liable</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign Worker</th>\n",
       "      <th>Good Customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1049</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2799</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>841</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2122</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2171</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Checking Status  Duration  Credit History  Purpose  Credit Amount  \\\n",
       "0                1        18               4        2           1049   \n",
       "1                1         9               4        0           2799   \n",
       "2                2        12               2        9            841   \n",
       "3                1        12               4        0           2122   \n",
       "4                1        12               4        0           2171   \n",
       "\n",
       "   Savings Account/Bonds  Employment Since  Installment Rate  Personal Status  \\\n",
       "0                      1                 2                 4                2   \n",
       "1                      1                 3                 2                3   \n",
       "2                      2                 4                 2                2   \n",
       "3                      1                 3                 3                3   \n",
       "4                      1                 3                 4                3   \n",
       "\n",
       "   Debtors/Guarantors  ...  Property Type  Age  Other Installment Plans  \\\n",
       "0                   1  ...              2   21                        3   \n",
       "1                   1  ...              1   36                        3   \n",
       "2                   1  ...              1   23                        3   \n",
       "3                   1  ...              1   39                        3   \n",
       "4                   1  ...              2   38                        1   \n",
       "\n",
       "   Housing Ownership  Number Existing Credits  Job  Number Liable  Telephone  \\\n",
       "0                  1                        1    3              2          1   \n",
       "1                  1                        2    3              1          1   \n",
       "2                  1                        1    2              2          1   \n",
       "3                  1                        2    2              1          1   \n",
       "4                  2                        2    2              2          1   \n",
       "\n",
       "   Foreign Worker  Good Customer  \n",
       "0               2              1  \n",
       "1               2              1  \n",
       "2               2              1  \n",
       "3               1              1  \n",
       "4               1              1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sage.datasets.credit()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit Amount</th>\n",
       "      <th>Installment Rate</th>\n",
       "      <th>Residence Duration</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number Existing Credits</th>\n",
       "      <th>Number Liable</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign Worker</th>\n",
       "      <th>Checking Status_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Other Installment Plans_1</th>\n",
       "      <th>Other Installment Plans_2</th>\n",
       "      <th>Other Installment Plans_3</th>\n",
       "      <th>Housing Ownership_1</th>\n",
       "      <th>Housing Ownership_2</th>\n",
       "      <th>Housing Ownership_3</th>\n",
       "      <th>Job_1</th>\n",
       "      <th>Job_2</th>\n",
       "      <th>Job_3</th>\n",
       "      <th>Job_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1049</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2799</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>841</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>2122</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>2171</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration  Credit Amount  Installment Rate  Residence Duration  Age  \\\n",
       "0        18           1049                 4                   4   21   \n",
       "1         9           2799                 2                   2   36   \n",
       "2        12            841                 2                   4   23   \n",
       "3        12           2122                 3                   2   39   \n",
       "4        12           2171                 4                   4   38   \n",
       "\n",
       "   Number Existing Credits  Number Liable  Telephone  Foreign Worker  \\\n",
       "0                        1              2          1               2   \n",
       "1                        2              1          1               2   \n",
       "2                        1              2          1               2   \n",
       "3                        2              1          1               1   \n",
       "4                        2              2          1               1   \n",
       "\n",
       "   Checking Status_1  ...  Other Installment Plans_1  \\\n",
       "0                  1  ...                          0   \n",
       "1                  1  ...                          0   \n",
       "2                  0  ...                          0   \n",
       "3                  1  ...                          0   \n",
       "4                  1  ...                          1   \n",
       "\n",
       "   Other Installment Plans_2  Other Installment Plans_3  Housing Ownership_1  \\\n",
       "0                          0                          1                    1   \n",
       "1                          0                          1                    1   \n",
       "2                          0                          1                    1   \n",
       "3                          0                          1                    1   \n",
       "4                          0                          0                    0   \n",
       "\n",
       "   Housing Ownership_2  Housing Ownership_3  Job_1  Job_2  Job_3  Job_4  \n",
       "0                    0                    0      0      0      1      0  \n",
       "1                    0                    0      0      0      1      0  \n",
       "2                    0                    0      0      1      0      0  \n",
       "3                    0                    0      0      1      0      0  \n",
       "4                    1                    0      0      1      0      0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Property, other installment, housing, job, status of checking act, credit history, purpose, savings, employment since, marital status, old debtors\n",
    "n = df.shape[0]\n",
    "X_df = df.drop([\"Good Customer\"], axis=1)\n",
    "y = df[\"Good Customer\"]\n",
    "\n",
    "categorical_columns = [\n",
    "    'Checking Status', 'Credit History', 'Purpose', #'Credit Amount', # It's listed but has 923 unique values\n",
    "    'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "    'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "    'Housing Ownership', 'Job', #'Telephone', 'Foreign Worker' # These are just binary\n",
    "]\n",
    "# feature_names = df.columns.tolist()[:-1]\n",
    "# categorical_inds = [feature_names.index(col) for col in categorical_columns]\n",
    "# print([pd.unique(df[colname]).shape[0] for colname in categorical_columns])\n",
    "X_binarized = pd.get_dummies(X_df, columns=categorical_columns)\n",
    "d_bin = X_binarized.shape[1]\n",
    "X_binarized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [9, 10, 11, 12],\n",
       " 1: [0],\n",
       " 2: [13, 14, 15, 16, 17],\n",
       " 3: [18, 19, 20, 21, 22, 23, 24, 25, 26, 27],\n",
       " 4: [1],\n",
       " 5: [28, 29, 30, 31, 32],\n",
       " 6: [33, 34, 35, 36, 37],\n",
       " 7: [2],\n",
       " 8: [38, 39, 40, 41],\n",
       " 9: [42, 43, 44],\n",
       " 10: [3],\n",
       " 11: [45, 46, 47, 48],\n",
       " 12: [4],\n",
       " 13: [49, 50, 51],\n",
       " 14: [52, 53, 54],\n",
       " 15: [5],\n",
       " 16: [55, 56, 57, 58],\n",
       " 17: [6],\n",
       " 18: [7],\n",
       " 19: [8]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict = {}\n",
    "for i, col in enumerate(X_df.columns):\n",
    "    bin_cols = []\n",
    "    for j, bin_col in enumerate(X_binarized.columns):\n",
    "        if bin_col.startswith(col):\n",
    "            bin_cols.append(j)\n",
    "    mapping_dict[i] = bin_cols\n",
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "n_train = round(n*0.8)\n",
    "train_idx = np.random.choice(n, n_train, replace=False)\n",
    "X_train, y_train = X_norm.iloc[train_idx].to_numpy(), y.iloc[train_idx].to_numpy()\n",
    "test_idx = np.setdiff1d(np.arange(n),train_idx)\n",
    "X_test, y_test = X_norm.iloc[test_idx].to_numpy(), y.iloc[test_idx].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 74.0\n",
      "Class imbalance: 69.5\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(np.mean(logreg.predict(X_test)==y_test)*100))\n",
    "print(\"Class imbalance: {}\".format(100*np.mean(y_train))) # 70% --> 74%. not amazing... but could be worse\n",
    "\n",
    "BETA = logreg.coef_.reshape(d_bin)\n",
    "INTERCEPT = logreg.intercept_\n",
    "\n",
    "def model(x):\n",
    "    yhat = sigmoid(np.dot(x, BETA) + INTERCEPT)\n",
    "    return yhat.item() if x.shape[0]==1 else yhat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recondition covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = np.cov(X_train, rowvar=False)\n",
    "# Recondition covariance\n",
    "u, s, vh = np.linalg.svd(cov_mat, full_matrices=True)\n",
    "K = 10000\n",
    "if np.max(s)/np.min(s) < K:\n",
    "    cov2 = cov_mat\n",
    "else:\n",
    "    s_max = s[0]\n",
    "    min_acceptable = s_max/K\n",
    "    s2 = np.copy(s)\n",
    "    s2[s <= min_acceptable] = min_acceptable\n",
    "    cov2 = np.matmul(u, np.matmul(np.diag(s2), vh))\n",
    "\n",
    "# Prepare for dependent sampling\n",
    "M_linear = 1000 # 20 seconds/1000 perms\n",
    "D_matrices = make_all_lundberg_matrices(M_linear, cov2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose test point and compute gradient and hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05712682 0.94287318]]\n",
      "0.9428731769700575\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "xloc = X_test[20:21]\n",
    "print(logreg.predict_proba(xloc))\n",
    "print(model(xloc)) # Yes, our function matches sklearn\n",
    "print(y_test[0]) # Correct classification\n",
    "\n",
    "gradient = logreg_gradient(model, xloc, BETA)\n",
    "hessian = logreg_hessian(model, xloc, BETA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SHAP values, assuming independent features\n",
    "#### Sanity check: Verify true SHAP values of the quadratic approximation add up to $f(x)-Ef(X)$\n",
    "#### They're close (but not perfect...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20438444228809766\n",
      "0.2043137720490672\n"
     ]
    }
   ],
   "source": [
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = np.cov(X_train, rowvar=False)\n",
    "\n",
    "avg_CV_empirical = np.mean(f_second_order_approx(model(xloc),X_train, xloc, gradient, hessian))\n",
    "pred = model(xloc)\n",
    "exp_CV_sum_empirical = pred - avg_CV_empirical\n",
    "shap_CV_true_indep = compute_true_shap_cv_indep(xloc, gradient, hessian, feature_means, cov_mat, mapping_dict=mapping_dict)\n",
    "sum_shap_CV_true = np.sum(shap_CV_true_indep)\n",
    "print(sum_shap_CV_true)\n",
    "print(exp_CV_sum_empirical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Sampling\n",
    "### Amazing! 95+% Variance reductions\n",
    "- Weird that we get a correlation of slightly over 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9967 0.9843 0.9811 0.9881 0.9937 0.9737 0.9842 0.9844 0.9972 0.9793\n",
      " 0.9885 0.9948 0.9773 0.9812 1.0041 0.9766 0.9936 0.9933 0.9726 0.9771]\n",
      "[ 99.  97.  96.  98.  99.  95.  97.  97.  99.  96.  98.  99.  96.  96.\n",
      " 101.  95.  99.  99.  95.  95.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "independent_features = True\n",
    "obj_ss = cv_shapley_sampling(model, X_train, xloc, \n",
    "                        independent_features,\n",
    "                        gradient, hessian,\n",
    "                        mapping_dict=mapping_dict,\n",
    "                        M=100, n_samples_per_perm=10) # M is number of permutations\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_ss\n",
    "\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(corr_ests[order], 4)) # Correlations\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5  7 11  1  3  8 18 12  2 13 15  6 10  9  4 19 16 14 17]\n",
      "[ 0  5  7 11  1  3  8 18  2 12 13 15  6 10  9  4 19 16 14 17]\n",
      "[ 0  5  7 11  1  3  8  2 18 12 13  6 15 10  9 19 16  4 14 17]\n",
      "[ 0  5  7 11  1  3  8  2 18 12 13  6 15 10  9 19 16 14 17  4]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(np.abs(shap_CV_true_indep))[::-1])\n",
    "print(np.argsort(np.abs(final_ests))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_model))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_CV))[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP\n",
    "### BAD: CV-adjusted KernelSHAP values are nonsensical\n",
    "### The correlations close to 1 must somehow be throwing the (co)variance off. \n",
    "### However, using many bootstrapped samples or samples per perm (for WLS) doesn't fix.\n",
    "Holds for all local x.\n",
    "The features that blow up are the ones with correlations closest to 1.\n",
    "When corr(A, B)=1, cov(A, B) = sA*sB*corr(A, B) =ish sA sB; cov(A, B)/var(B) = sA/sB\n",
    "- Small standard deviation of the quadratic model --> blows up\n",
    "- Not sure what the pattern is here \n",
    "\n",
    "0.95*corr(A,B) = 0.95*(Cov(A,B)/(sqrt(VarA)*sqrt(VarA))) = Cov(A,B)/(sqrt(VarA)*(sqrt(VarB)/0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9954 0.9937 0.9915 0.99   0.99   0.993  0.9902 0.9971 0.9936 0.9885\n",
      " 0.9891 0.997  0.9905 0.9962 0.9937 0.9886 0.984  0.9888 0.9873 0.9868]\n",
      "[99. 99. 98. 98. 98. 99. 98. 99. 99. 98. 98. 99. 98. 99. 99. 98. 97. 98.\n",
      " 97. 97.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "independent_features = True\n",
    "obj_kshap = cv_kshap(model, X_train, xloc, \n",
    "            independent_features,\n",
    "            gradient, hessian,\n",
    "            mapping_dict=mapping_dict,\n",
    "            M=1000, n_samples_per_perm=10, \n",
    "            var_method='wls') # n_boot=1000\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "# print(np.round(final_ests[order], 3)) # Final SHAP estimates, ordered\n",
    "print(np.round(corr_ests[order], 4)) # Correlations\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5  7 11  1  3  8 18 12  2 13 15  6 10  9  4 19 16 14 17]\n",
      "[12  0  2  9 17  4  7 18 10 14 19  5  3 13 11  1  8  6 15 16]\n",
      "[ 0  5  7  1 11  3  8  2 12 18 13  9 15 16 19 10  6 14 17  4]\n",
      "[ 0  5  7  1 11  3  8 12  2 18 13  9 15 19 10  6 16 17  4 14]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(np.abs(shap_CV_true_indep))[::-1])\n",
    "print(np.argsort(np.abs(final_ests))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_model))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_CV))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11  0.068 0.044 0.041 0.038 0.033 0.024 0.021 0.019 0.016 0.015 0.014\n",
      " 0.01  0.008 0.007 0.006 0.005 0.003 0.003 0.001]\n",
      "[0.074 0.038 0.036 0.024 0.022 0.02  0.019 0.015 0.011 0.007 0.006 0.005\n",
      " 0.005 0.003 0.003 0.002 0.001 0.001 0.001 0.   ]\n",
      "[0.091 0.061 0.032 0.03  0.029 0.019 0.018 0.017 0.016 0.016 0.009 0.009\n",
      " 0.008 0.005 0.003 0.003 0.002 0.002 0.002 0.001]\n",
      "[0.091 0.059 0.038 0.037 0.033 0.027 0.022 0.017 0.016 0.015 0.014 0.011\n",
      " 0.008 0.006 0.005 0.005 0.004 0.002 0.001 0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.sort(np.abs(vshap_ests_model))[::-1],3))\n",
    "print(np.round(np.sort(np.abs(final_ests))[::-1],3)) \n",
    "\n",
    "print(np.round(np.sort(np.abs(shap_CV_true_indep))[::-1],3))\n",
    "print(np.round(np.sort(np.abs(vshap_ests_CV))[::-1],3)) \n",
    "# gradient[mapping_dict[15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Sampling\n",
    "#### Looks great. Variance reductions around 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n",
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29761154 -0.29003999  0.1133286   0.08551847 -0.0722926   0.04231113\n",
      "  0.02981682  0.02805542  0.02220855  0.02123222 -0.01887437  0.01792289\n",
      "  0.01653279  0.01488199  0.01065719  0.00923593  0.00649017  0.00599089\n",
      "  0.0046796  -0.00177476]\n",
      "[0.95 0.96 0.96 0.95 0.94 0.95 0.96 0.96 0.94 0.94 0.94 0.92 0.96 0.96\n",
      " 0.94 0.93 0.95 0.96 0.96 0.95]\n",
      "[90. 93. 93. 90. 89. 91. 93. 92. 89. 88. 88. 85. 92. 92. 87. 87. 90. 91.\n",
      " 92. 91.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "independent_features = False\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient, mapping_dict=mapping_dict)\n",
    "obj_dep = cv_shapley_sampling(model, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    shap_CV_true=shap_CV_true_dep, # Equivalently, can give D_matrices instead\n",
    "                    M=100,n_samples_per_perm=10,\n",
    "                    mapping_dict=mapping_dict,\n",
    "                    cov_mat=cov2)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(final_ests[order]) # Final SHAP estimates, ordered\n",
    "print(np.round(corr_ests[order], 2)) # Correlations\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 11  0  1  5  7  8 18  3 14 13 12 16  4  9 10  6 19 15 17]\n",
      "[11  2  0  5  1  7  3 18 14 12  8 16 13  6  4 17 10 19  9 15]\n",
      "[ 0  5  3 11  6  7 12 10 14 17 16 18 13 19  4  9 15  8  2  1]\n",
      "[ 0  5 11  3  7  6 12 14 10 17 18 16 13 19 15  9  4  1  8  2]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(np.abs(shap_CV_true_dep))[::-1])\n",
    "print(np.argsort(np.abs(final_ests))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_model))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_CV))[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelSHAP\n",
    "#### Now nothing blows up, thankfully. Around 90% variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.46756283e-01  3.18031034e-01  1.13934832e-01 -8.29129006e-02\n",
      "  7.44877271e-02  3.57837259e-02  2.69689342e-02 -2.26610431e-02\n",
      "  2.04179699e-02  1.99757946e-02  1.74992680e-02  1.53527456e-02\n",
      "  1.41060741e-02 -1.24227922e-02  4.60352323e-03 -2.78228726e-03\n",
      "  2.35980691e-03  1.06218289e-03  6.13316107e-04 -1.74501905e-04]\n",
      "[0.94 0.92 0.9  0.97 0.84 0.92 0.91 0.97 0.94 0.97 0.92 0.93 0.97 0.95\n",
      " 0.96 0.97 0.9  0.94 0.9  0.94]\n",
      "[88. 85. 82. 93. 70. 86. 82. 95. 88. 93. 84. 86. 94. 90. 92. 94. 81. 89.\n",
      " 81. 89.]\n"
     ]
    }
   ],
   "source": [
    "%run helper_dep\n",
    "np.random.seed(1)\n",
    "independent_features = False\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient, mapping_dict=mapping_dict)\n",
    "obj_kshap_dep = cv_kshap(model, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    shap_CV_true=shap_CV_true_dep,\n",
    "                    M=1000,n_samples_per_perm=10,\n",
    "                    mapping_dict=mapping_dict,\n",
    "                    cov_mat=cov2)\n",
    "\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(final_ests[order]) # Final SHAP estimates, ordered\n",
    "print(np.round(corr_ests[order], 2)) # Correlations\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 11  0  1  5  7  8 18  3 14 13 12 16  4  9 10  6 19 15 17]\n",
      "[ 2 11  0  1  5  7  3  8 18 14 12  6 13  4 16 10  9 15 17 19]\n",
      "[ 0  5  1 11  8  7  3 13 14 12  2  6  9 10 18 17 16 19  4 15]\n",
      "[ 0  1  5  7  8 11  2  3 13 14 18 12  4 10 16 17 15 19  9  6]\n"
     ]
    }
   ],
   "source": [
    "print(np.argsort(np.abs(shap_CV_true_dep))[::-1])\n",
    "print(np.argsort(np.abs(final_ests))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_model))[::-1])\n",
    "print(np.argsort(np.abs(vshap_ests_CV))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
