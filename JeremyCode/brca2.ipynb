{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "sys.path.append(\"../GilesCode\")\n",
    "from helper import *\n",
    "from helper2_dep import *\n",
    "from helper2_indep import *\n",
    "from helper2_shapley_sampling import *\n",
    "from helper4_kshap import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from os.path import join\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "np.random.seed(1)\n",
    "data = pd.read_csv('../Data/brca_small.csv')\n",
    "X = data.values[:, :-1][:,:25]\n",
    "Y = data.values[:, -1]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=100, random_state=0)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=100, random_state=1)\n",
    "\n",
    "# Normalize\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_model(x, y, x_val, y_val):\n",
    "    # Cross validate for C\n",
    "    C_list = np.arange(0.1, 1.0, 0.05)\n",
    "    best_loss = np.inf\n",
    "    best_C = None\n",
    "\n",
    "    for C in C_list:\n",
    "        # Fit model\n",
    "        model = LogisticRegression(C=C, penalty='l1', multi_class='multinomial',\n",
    "                                   solver='saga', max_iter=20000)\n",
    "        model.fit(x, y)\n",
    "\n",
    "        # Calculate loss\n",
    "        val_loss = log_loss(y_val, model.predict_proba(x_val))\n",
    "\n",
    "        # See if best\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_C = C\n",
    "            \n",
    "    # Train model with all data\n",
    "    model = LogisticRegression(C=best_C, penalty='l1', multi_class='multinomial',\n",
    "                               solver='saga', max_iter=10000)\n",
    "    model.fit(np.concatenate((x, x_val), axis=0),\n",
    "              np.concatenate((y, y_val), axis=0))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "model = fit_model(X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "# OK, now let's get a gradient and hessian\n",
    "\n",
    "d = X_train.shape[1]\n",
    "\n",
    "BETA = model.coef_\n",
    "A = model.intercept_.reshape(4,1)\n",
    "\n",
    "\n",
    "def modelf(x):\n",
    "    yhat = np.exp(A+np.dot(BETA,x.T))\n",
    "    #return yhat.item() if x.shape[0]==1 else yhat\n",
    "    return yhat[1]/np.sum(yhat)\n",
    "\n",
    "\n",
    "def modelg(x):\n",
    "    yhat = np.exp(A+np.dot(BETA,x.T))\n",
    "    yhat = yhat/np.sum(yhat)\n",
    "    \n",
    "    return BETA[1]*yhat[1] - yhat[1]*np.dot(yhat.T,BETA)\n",
    "    \n",
    "def modelH(x):\n",
    "    yhat = np.exp(A+np.dot(BETA,x.T))\n",
    "    yhat = yhat/np.sum(yhat)\n",
    "    \n",
    "    return yhat[1]*(np.outer(BETA[1],BETA[1].T) -\n",
    "        np.dot(np.dot(BETA.T,np.diagflat(yhat)),BETA) +\n",
    "        np.outer(np.dot(yhat.T,BETA),np.dot(yhat.T,BETA)))\n",
    "\n",
    "xloc = X_train[1].reshape(1,-1)\n",
    "modelf(xloc)\n",
    "gradient = modelg(xloc).T\n",
    "hessian = modelH(xloc) # Not H?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52. 13.  0. 39. 46. 44.  8. 13. 29. 41. 29. 18.  0.  0. 31. 51.  0. 32.\n",
      "  2.  0.  0.  0. 21. 18. 11.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = True\n",
    "obj_ss = cv_shapley_sampling(modelf, X_train, xloc, \n",
    "                        independent_features,\n",
    "                        gradient, hessian,\n",
    "                        M=100, n_samples_per_perm=10) # M is number of permutations\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_ss\n",
    "\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(np.maximum(corr_ests, 0)**2**2)[order])) # Variance reductions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66. 61. 64. 69. 68. 46. 55. 32. 49. 54. 63. 74. 67. 49. 69. 52. 64. 63.\n",
      " 58. 65. 73. 50. 53. 57. 60.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = True\n",
    "obj_kshap = cv_kshap(modelf, X_train, xloc, \n",
    "            independent_features,\n",
    "            gradient, hessian,\n",
    "            var_method=\"wls\",\n",
    "            M=1000, n_samples_per_perm=10)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap\n",
    "\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = np.cov(X_train, rowvar=False)\n",
    "\n",
    "# Now to set up D matrices\n",
    "u, s, vh = np.linalg.svd(cov_mat, full_matrices=True)\n",
    "K = 10000\n",
    "s_max = s[0]\n",
    "min_acceptable = s_max/K\n",
    "s2 = np.copy(s)\n",
    "s2[s <= min_acceptable] = min_acceptable\n",
    "cov2 = np.matmul(u, np.matmul(np.diag(s2), vh))\n",
    "\n",
    "M_linear = 1000 # 10 seconds/1000 perms or so\n",
    "D_matrices = make_all_lundberg_matrices(M_linear, cov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 10.  8.  9. 29. 27. 29. 31. 40. 15. 17. 41. 28. 12. 16. 20. 29. 31.\n",
      " 32. 23.  9. 21. 13. 30. 38.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = False\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient)\n",
    "obj_dep = cv_shapley_sampling(modelf, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    shap_CV_true=shap_CV_true_dep, # Equivalently, can give D_matrices instead\n",
    "                    M=50,n_samples_per_perm=1,\n",
    "                    cov_mat=cov2)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21. 18. 21. 18. 24. 26. 28. 24. 24. 30. 21. 25. 28. 21. 21. 27. 23. 26.\n",
      " 19. 15. 19. 17. 24. 26. 21.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "independent_features = False\n",
    "obj_kshap_dep = cv_kshap(modelf, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    shap_CV_true=shap_CV_true_dep,\n",
    "                    M=1000,n_samples_per_perm=10, var_method=\"wls\",\n",
    "                    cov_mat=cov2)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(corr_ests**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
