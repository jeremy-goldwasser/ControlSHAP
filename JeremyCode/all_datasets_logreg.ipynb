{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremygoldwasser/opt/anaconda3/envs/shap/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "sys.path.append('../GilesCode/')\n",
    "from helper import *\n",
    "from helper2 import *\n",
    "from helper2_dep import *\n",
    "from helper2_indep import *\n",
    "from helper2_shapley_sampling import *\n",
    "from helper4_kshap import *\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = 10\n",
    "# FEATURE_MEANS = np.repeat(0, d)\n",
    "# FEATURE_VARS = np.repeat(1, d)\n",
    "# FEATURE_COVS = [0.5, 0.25]\n",
    "# COV_MAT = make_banded_cov(FEATURE_VARS, FEATURE_COVS)\n",
    "\n",
    "# # Randomly generate samples\n",
    "# np.random.seed(1)\n",
    "# X = np.random.multivariate_normal(FEATURE_MEANS, COV_MAT, size=10000)\n",
    "# X_train, X_test = X[:8000], X[8000:]\n",
    "# xloc = X_test[10].reshape((1,d))\n",
    "\n",
    "# np.random.seed(1)\n",
    "# BETA = np.random.normal(0, 1, size = d)\n",
    "# def model(x):\n",
    "#     yhat = sigmoid(np.dot(x, BETA))\n",
    "#     return yhat.item() if x.shape[0]==1 else yhat\n",
    "# y = (model(X) > 0.5).astype(int)\n",
    "# y_train, y_test = y[:8000], y[8000:]\n",
    "# mapping_dict = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = shap.datasets.adult()\n",
    "# X_display, y_display = shap.datasets.adult(display=True)\n",
    "# X_binarized = pd.get_dummies(X_display)\n",
    "\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(X_display.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_binarized.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols\n",
    "\n",
    "# X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "# y_int = y_display.astype(\"int8\")\n",
    "\n",
    "# # Split into training and test sets\n",
    "# np.random.seed(1)\n",
    "# n, d = X_norm.shape\n",
    "# n_train = round(n*0.75)\n",
    "# train_idx = np.random.choice(n, size=n_train, replace=False)\n",
    "# X_train_pd, y_train = X_norm.iloc[train_idx], y_int[train_idx]\n",
    "# X_train = X_train_pd.to_numpy()\n",
    "\n",
    "# test_idx = np.setdiff1d(list(range(n)), train_idx)\n",
    "# X_test_pd, y_test = X_norm.iloc[test_idx], y_int[test_idx]\n",
    "# X_test = X_test_pd.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirpath = \"../Data/bank\"\n",
    "# # dirpath = /PATH/TO/DATA\n",
    "# df_orig = pd.read_csv(join(dirpath, \"df_orig.csv\"))\n",
    "\n",
    "# X_train_raw = np.load(join(dirpath, \"X_train.npy\"))\n",
    "# X_test_raw = np.load(join(dirpath, \"X_test.npy\"))\n",
    "# y_train = np.load(join(dirpath, \"Y_train.npy\"))\n",
    "# y_test = np.load(join(dirpath, \"Y_test.npy\"))\n",
    "# full_dim = X_train_raw.shape[1] # dimension including all binarized categorical columns\n",
    "# X_df = pd.read_csv(join(dirpath, \"X_df.csv\"))\n",
    "\n",
    "\n",
    "# trainmean, trainstd = np.mean(X_train_raw, axis=0), np.std(X_train_raw, axis=0)\n",
    "# def rescale(x, trainmean, trainstd):\n",
    "#     return (x - trainmean) / trainstd\n",
    "# X_train = rescale(X_train_raw, trainmean, trainstd)\n",
    "# X_test = rescale(X_test_raw, trainmean, trainstd)\n",
    "\n",
    "# feature_means = np.mean(X_train, axis=0)\n",
    "# cov_mat = np.cov(X_train, rowvar=False)\n",
    "\n",
    "\n",
    "# df_orig.columns = df_orig.columns.str.replace(' ', '_')\n",
    "# categorical_cols = ['Job', 'Marital', 'Education', 'Default', 'Housing',\n",
    "#                     'Loan', 'Contact', 'Month', 'Prev_Outcome']\n",
    "# mapping_dict = get_mapping_dict(df_orig, X_df, X_train_raw, categorical_cols)\n",
    "# mapping_dict\n",
    "\n",
    "# d = X_df.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Credit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sage\n",
    "# df = sage.datasets.credit()\n",
    "# # Property, other installment, housing, job, status of checking act, credit history, purpose, savings, employment since, marital status, old debtors\n",
    "# n = df.shape[0]\n",
    "# X_df = df.drop([\"Good Customer\"], axis=1)\n",
    "# y = df[\"Good Customer\"]\n",
    "\n",
    "# categorical_columns = [\n",
    "#     'Checking Status', 'Credit History', 'Purpose', #'Credit Amount', # It's listed but has 923 unique values\n",
    "#     'Savings Account/Bonds', 'Employment Since', 'Personal Status',\n",
    "#     'Debtors/Guarantors', 'Property Type', 'Other Installment Plans',\n",
    "#     'Housing Ownership', 'Job', #'Telephone', 'Foreign Worker' # These are just binary\n",
    "# ]\n",
    "# X_binarized = pd.get_dummies(X_df, columns=categorical_columns)\n",
    "# d_bin = X_binarized.shape[1]\n",
    "\n",
    "# mapping_dict = {}\n",
    "# for i, col in enumerate(X_df.columns):\n",
    "#     bin_cols = []\n",
    "#     for j, bin_col in enumerate(X_binarized.columns):\n",
    "#         if bin_col.startswith(col):\n",
    "#             bin_cols.append(j)\n",
    "#     mapping_dict[i] = bin_cols\n",
    "\n",
    "# np.random.seed(1)\n",
    "# X_norm = (X_binarized-X_binarized.min())/(X_binarized.max()-X_binarized.min())\n",
    "# n_train = round(n*0.8)\n",
    "# train_idx = np.random.choice(n, n_train, replace=False)\n",
    "# X_train, y_train = X_norm.iloc[train_idx].to_numpy(), y.iloc[train_idx].to_numpy()\n",
    "# test_idx = np.setdiff1d(np.arange(n),train_idx)\n",
    "# X_test, y_test = X_norm.iloc[test_idx].to_numpy(), y.iloc[test_idx].to_numpy()\n",
    "# d = X_train.shape[1] # dimension of binarized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "np.random.seed(1)\n",
    "data = pd.read_csv('../Data/brca_small.csv')\n",
    "X = data.values[:, :-1][:,:20]\n",
    "Y = data.values[:, -1]\n",
    "Y = (Y==2).astype(int)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=100, random_state=0)\n",
    "\n",
    "# Normalize\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "# X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "d = X_train.shape[1]\n",
    "mapping_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds = []\n",
    "for i in range(d):\n",
    "    uu = np.unique(X_train[:,i])\n",
    "    if len(uu) == 2:\n",
    "        sds.append(uu)\n",
    "    else:\n",
    "        sds.append(np.repeat(np.std(X_train[:,i]),2))\n",
    "sds = np.array(sds)\n",
    "\n",
    "feature_means = np.mean(X_train, axis=0)\n",
    "cov_mat = np.cov(X_train, rowvar=False)\n",
    "# Recondition covariance\n",
    "u, s, vh = np.linalg.svd(cov_mat, full_matrices=True)\n",
    "K = 10000\n",
    "if np.max(s)/np.min(s) < K:\n",
    "    cov2 = cov_mat\n",
    "else:\n",
    "    s_max = s[0]\n",
    "    min_acceptable = s_max/K\n",
    "    s2 = np.copy(s)\n",
    "    s2[s <= min_acceptable] = min_acceptable\n",
    "    cov2 = np.matmul(u, np.matmul(np.diag(s2), vh))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance: 55.00000000000001\n",
      "Estimation accuracy: 80.0\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Class imbalance: {}\".format(100*(max(np.mean(y_test), 1-np.mean(y_test)))))\n",
    "print(\"Estimation accuracy: {}\".format(np.mean((logreg.predict(X_test) > 0.5)==y_test)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.54646748e-03, -3.23152384e-03, -5.73285701e-04,\n",
       "         3.05522989e-03, -8.70348573e-03, -5.59504094e-03,\n",
       "         5.02012330e-03, -6.99243644e-04, -5.06503693e-03,\n",
       "         6.43905690e-03, -4.84344098e-04, -1.43364501e-04,\n",
       "        -1.25581807e-03,  9.18165968e-04, -4.13602322e-03,\n",
       "         2.95306350e-03,  1.43874720e-03,  4.48174441e-03,\n",
       "        -6.24031159e-03, -5.03249254e-03],\n",
       "       [-3.23152384e-03,  2.29689234e-03,  4.07478206e-04,\n",
       "        -2.17158668e-03,  6.18623619e-03,  3.97682559e-03,\n",
       "        -3.56818743e-03,  4.97006196e-04,  3.60011100e-03,\n",
       "        -4.57673260e-03,  3.44260573e-04,  1.01900169e-04,\n",
       "         8.92606415e-04, -6.52611116e-04,  2.93978957e-03,\n",
       "        -2.09896918e-03, -1.02262820e-03, -3.18552019e-03,\n",
       "         4.43546902e-03,  3.57697920e-03],\n",
       "       [-5.73285701e-04,  4.07478206e-04,  7.22883200e-05,\n",
       "        -3.85248464e-04,  1.09746390e-03,  7.05505315e-04,\n",
       "        -6.33011216e-04,  8.81709559e-05,  6.38674589e-04,\n",
       "        -8.11931301e-04,  6.10732502e-05,  1.80775116e-05,\n",
       "         1.58352072e-04, -1.15775913e-04,  5.21530834e-04,\n",
       "        -3.72365818e-04, -1.81418475e-04, -5.65124463e-04,\n",
       "         7.86870559e-04,  6.34570913e-04],\n",
       "       [ 3.05522989e-03, -2.17158668e-03, -3.85248464e-04,\n",
       "         2.05311700e-03, -5.84874958e-03, -3.75987212e-03,\n",
       "         3.37352699e-03, -4.69892305e-04, -3.40370899e-03,\n",
       "         4.32705154e-03, -3.25479633e-04, -9.63410628e-05,\n",
       "        -8.43910778e-04,  6.17008287e-04, -2.77941101e-03,\n",
       "         1.98446111e-03,  9.66839302e-04,  3.01173594e-03,\n",
       "        -4.19349453e-03, -3.38183913e-03],\n",
       "       [-8.70348573e-03,  6.18623619e-03,  1.09746390e-03,\n",
       "        -5.84874958e-03,  1.66614331e-02,  1.07108121e-02,\n",
       "        -9.61022415e-03,  1.33859026e-03,  9.69620411e-03,\n",
       "        -1.23265459e-02,  9.27199406e-04,  2.74448436e-04,\n",
       "         2.40406309e-03, -1.75768208e-03,  7.91775578e-03,\n",
       "        -5.65316836e-03, -2.75425169e-03, -8.57958377e-03,\n",
       "         1.19460797e-02,  9.63390308e-03],\n",
       "       [-5.59504094e-03,  3.97682559e-03,  7.05505315e-04,\n",
       "        -3.75987212e-03,  1.07108121e-02,  6.88545190e-03,\n",
       "        -6.17793826e-03,  8.60513539e-04,  6.23321053e-03,\n",
       "        -7.92412729e-03,  5.96050685e-04,  1.76429339e-04,\n",
       "         1.54545338e-03, -1.12992696e-03,  5.08993398e-03,\n",
       "        -3.63414261e-03, -1.77057232e-03, -5.51539049e-03,\n",
       "         7.67954439e-03,  6.19316028e-03],\n",
       "       [ 5.02012330e-03, -3.56818743e-03, -6.33011216e-04,\n",
       "         3.37352699e-03, -9.61022415e-03, -6.17793826e-03,\n",
       "         5.54312509e-03, -7.72091592e-04, -5.59271787e-03,\n",
       "         7.10988471e-03, -5.34803581e-04, -1.58300367e-04,\n",
       "        -1.38665053e-03,  1.01382148e-03, -4.56691853e-03,\n",
       "         3.26071680e-03,  1.58863741e-03,  4.94865732e-03,\n",
       "        -6.89043389e-03, -5.55678297e-03],\n",
       "       [-6.99243644e-04,  4.97006196e-04,  8.81709559e-05,\n",
       "        -4.69892305e-04,  1.33859026e-03,  8.60513539e-04,\n",
       "        -7.72091592e-04,  1.07543203e-04,  7.78999278e-04,\n",
       "        -9.90322628e-04,  7.44917969e-05,  2.20493640e-05,\n",
       "         1.93143976e-04, -1.41213309e-04,  6.36117594e-04,\n",
       "        -4.54179184e-04, -2.21278353e-04, -6.89289281e-04,\n",
       "         9.59755731e-04,  7.73993973e-04],\n",
       "       [-5.06503693e-03,  3.60011100e-03,  6.38674589e-04,\n",
       "        -3.40370899e-03,  9.69620411e-03,  6.23321053e-03,\n",
       "        -5.59271787e-03,  7.78999278e-04,  5.64275434e-03,\n",
       "        -7.17349484e-03,  5.39588318e-04,  1.59716636e-04,\n",
       "         1.39905651e-03, -1.02289185e-03,  4.60777746e-03,\n",
       "        -3.28988952e-03, -1.60285050e-03, -4.99293156e-03,\n",
       "         6.95208066e-03,  5.60649794e-03],\n",
       "       [ 6.43905690e-03, -4.57673260e-03, -8.11931301e-04,\n",
       "         4.32705154e-03, -1.23265459e-02, -7.92412729e-03,\n",
       "         7.10988471e-03, -9.90322628e-04, -7.17349484e-03,\n",
       "         9.11948761e-03, -6.85965362e-04, -2.03043833e-04,\n",
       "        -1.77858614e-03,  1.30037726e-03, -5.85775419e-03,\n",
       "         4.18235565e-03,  2.03766443e-03,  6.34739113e-03,\n",
       "        -8.83800921e-03, -7.12740298e-03],\n",
       "       [-4.84344098e-04,  3.44260573e-04,  6.10732502e-05,\n",
       "        -3.25479633e-04,  9.27199406e-04,  5.96050685e-04,\n",
       "        -5.34803581e-04,  7.44917969e-05,  5.39588318e-04,\n",
       "        -6.85965362e-04,  5.15981267e-05,  1.52729015e-05,\n",
       "         1.33784762e-04, -9.78140215e-05,  4.40618667e-04,\n",
       "        -3.14595647e-04, -1.53272561e-04, -4.77449023e-04,\n",
       "         6.64792633e-04,  5.36121301e-04],\n",
       "       [-1.43364501e-04,  1.01900169e-04,  1.80775116e-05,\n",
       "        -9.63410628e-05,  2.74448436e-04,  1.76429339e-04,\n",
       "        -1.58300367e-04,  2.20493640e-05,  1.59716636e-04,\n",
       "        -2.03043833e-04,  1.52729015e-05,  4.52073622e-06,\n",
       "         3.95999162e-05, -2.89526774e-05,  1.30421896e-04,\n",
       "        -9.31194335e-05, -4.53682503e-05, -1.41323578e-04,\n",
       "         1.96776764e-04,  1.58690409e-04],\n",
       "       [-1.25581807e-03,  8.92606415e-04,  1.58352072e-04,\n",
       "        -8.43910778e-04,  2.40406309e-03,  1.54545338e-03,\n",
       "        -1.38665053e-03,  1.93143976e-04,  1.39905651e-03,\n",
       "        -1.77858614e-03,  1.33784762e-04,  3.95999162e-05,\n",
       "         3.46880085e-04, -2.53614355e-04,  1.14244581e-03,\n",
       "        -8.15690540e-04, -3.97408480e-04, -1.23794037e-03,\n",
       "         1.72368902e-03,  1.39006715e-03],\n",
       "       [ 9.18165968e-04, -6.52611116e-04, -1.15775913e-04,\n",
       "         6.17008287e-04, -1.75768208e-03, -1.12992696e-03,\n",
       "         1.01382148e-03, -1.41213309e-04, -1.02289185e-03,\n",
       "         1.30037726e-03, -9.78140215e-05, -2.89526774e-05,\n",
       "        -2.53614355e-04,  1.85425003e-04, -8.35276132e-04,\n",
       "         5.96375631e-04,  2.90557168e-04,  9.05095048e-04,\n",
       "        -1.26024034e-03, -1.01631946e-03],\n",
       "       [-4.13602322e-03,  2.93978957e-03,  5.21530834e-04,\n",
       "        -2.77941101e-03,  7.91775578e-03,  5.08993398e-03,\n",
       "        -4.56691853e-03,  6.36117594e-04,  4.60777746e-03,\n",
       "        -5.85775419e-03,  4.40618667e-04,  1.30421896e-04,\n",
       "         1.14244581e-03, -8.35276132e-04,  3.76263290e-03,\n",
       "        -2.68646797e-03, -1.30886053e-03, -4.07714321e-03,\n",
       "         5.67695113e-03,  4.57817110e-03],\n",
       "       [ 2.95306350e-03, -2.09896918e-03, -3.72365818e-04,\n",
       "         1.98446111e-03, -5.65316836e-03, -3.63414261e-03,\n",
       "         3.26071680e-03, -4.54179184e-04, -3.28988952e-03,\n",
       "         4.18235565e-03, -3.14595647e-04, -9.31194335e-05,\n",
       "        -8.15690540e-04,  5.96375631e-04, -2.68646797e-03,\n",
       "         1.91810105e-03,  9.34508355e-04,  2.91102398e-03,\n",
       "        -4.05326476e-03, -3.26875099e-03],\n",
       "       [ 1.43874720e-03, -1.02262820e-03, -1.81418475e-04,\n",
       "         9.66839302e-04, -2.75425169e-03, -1.77057232e-03,\n",
       "         1.58863741e-03, -2.21278353e-04, -1.60285050e-03,\n",
       "         2.03766443e-03, -1.53272561e-04, -4.53682503e-05,\n",
       "        -3.97408480e-04,  2.90557168e-04, -1.30886053e-03,\n",
       "         9.34508355e-04,  4.55297109e-04,  1.41826533e-03,\n",
       "        -1.97477071e-03, -1.59255171e-03],\n",
       "       [ 4.48174441e-03, -3.18552019e-03, -5.65124463e-04,\n",
       "         3.01173594e-03, -8.57958377e-03, -5.51539049e-03,\n",
       "         4.94865732e-03, -6.89289281e-04, -4.99293156e-03,\n",
       "         6.34739113e-03, -4.77449023e-04, -1.41323578e-04,\n",
       "        -1.23794037e-03,  9.05095048e-04, -4.07714321e-03,\n",
       "         2.91102398e-03,  1.41826533e-03,  4.41794274e-03,\n",
       "        -6.15147513e-03, -4.96085047e-03],\n",
       "       [-6.24031159e-03,  4.43546902e-03,  7.86870559e-04,\n",
       "        -4.19349453e-03,  1.19460797e-02,  7.67954439e-03,\n",
       "        -6.89043389e-03,  9.59755731e-04,  6.95208066e-03,\n",
       "        -8.83800921e-03,  6.64792633e-04,  1.96776764e-04,\n",
       "         1.72368902e-03, -1.26024034e-03,  5.67695113e-03,\n",
       "        -4.05326476e-03, -1.97477071e-03, -6.15147513e-03,\n",
       "         8.56521880e-03,  6.90741145e-03],\n",
       "       [-5.03249254e-03,  3.57697920e-03,  6.34570913e-04,\n",
       "        -3.38183913e-03,  9.63390308e-03,  6.19316028e-03,\n",
       "        -5.55678297e-03,  7.73993973e-04,  5.60649794e-03,\n",
       "        -7.12740298e-03,  5.36121301e-04,  1.58690409e-04,\n",
       "         1.39006715e-03, -1.01631946e-03,  4.57817110e-03,\n",
       "        -3.26875099e-03, -1.59255171e-03, -4.96085047e-03,\n",
       "         6.90741145e-03,  5.57047450e-03]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xloc = X_test[0:1]\n",
    "def fmodel(xloc):\n",
    "    return logreg.predict_proba(xloc)[:,1]\n",
    "\n",
    "BETA = logreg.coef_.reshape(-1)\n",
    "gradient = logreg_gradient(fmodel, xloc, BETA)\n",
    "hessian = logreg_hessian(fmodel, xloc, BETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3885982815356193\n",
      "[-0.38815471]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "gradient = difference_gradient(fmodel,xloc,sds)\n",
    "hessian = difference_hessian(fmodel,xloc,sds)\n",
    "\n",
    "shap_CV_true_indep = compute_true_shap_cv_indep(xloc, gradient, hessian, feature_means, cov_mat, mapping_dict=mapping_dict)\n",
    "sum_shap_CV_true = np.sum(shap_CV_true_indep)\n",
    "avg_CV_empirical = np.mean(f_second_order_approx(fmodel(xloc),X_train, xloc, gradient, hessian))\n",
    "pred = fmodel(xloc)#[0]\n",
    "exp_CV_sum_empirical = pred - avg_CV_empirical\n",
    "print(sum_shap_CV_true)\n",
    "print(exp_CV_sum_empirical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36. 10. 41. 17. 38. 19.  0.  0. 11.  0. 40.  1. 11.  0.  3. 14.  2.  0.\n",
      "  8.  0.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = True\n",
    "obj_ss = cv_shapley_sampling(fmodel, X_train, xloc, \n",
    "                        independent_features,\n",
    "                        gradient, hessian,\n",
    "                        mapping_dict=mapping_dict,\n",
    "                        M=100, n_samples_per_perm=10) # M is number of permutations\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_ss\n",
    "\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(np.maximum(corr_ests, 0)**2)[order])) # Variance reductions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16. 11. 13. 10. 13. 21. 18. 12. 15. 10. 11. 20. 15. 13. 16. 14. 11. 18.\n",
      " 14. 16.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = True\n",
    "obj_kshap = cv_kshap(fmodel, X_train, xloc, \n",
    "            independent_features,\n",
    "            gradient, hessian,\n",
    "            mapping_dict=mapping_dict,var_method=\"wls\",\n",
    "            M=1000, n_samples_per_perm=10)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap\n",
    "\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(np.maximum(corr_ests,0)**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for dependent sampling\n",
    "M_linear = 100\n",
    "D_matrices = make_all_lundberg_matrices(M_linear, cov2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27. 38. 14.  3.  0. 27. 18.  6. 25. 22. 35.  8. 11.  4. 10. 12. 10. 15.\n",
      " 12. 27.]\n"
     ]
    }
   ],
   "source": [
    "independent_features = False\n",
    "shap_CV_true_dep = linear_shap_vals(xloc, D_matrices, feature_means, gradient)\n",
    "obj_dep = cv_shapley_sampling(fmodel, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    mapping_dict=mapping_dict,\n",
    "                    shap_CV_true=shap_CV_true_dep, # Equivalently, can give D_matrices instead\n",
    "                    M=100,n_samples_per_perm=10,\n",
    "                    cov_mat=cov2)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(np.maximum(corr_ests,0)**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes get negligible variance reductions from bootstrapped covariance, but good ones from WLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 19. 10. 36. 18. 18. 23. 18. 23. 20. 24. 15. 31. 21. 22. 24. 24. 22.\n",
      " 21. 18.]\n"
     ]
    }
   ],
   "source": [
    "# Sometimes get negligible variance reductions from bootstrapped covariance, but good ones from WLS\n",
    "np.random.seed(2)\n",
    "independent_features = False\n",
    "obj_kshap_dep = cv_kshap(fmodel, X_train, xloc,\n",
    "                    independent_features,\n",
    "                    gradient,\n",
    "                    mapping_dict=mapping_dict,\n",
    "                    shap_CV_true=shap_CV_true_dep,\n",
    "                    M=1000,n_samples_per_perm=10, var_method=\"wls\",\n",
    "                    cov_mat=cov2)\n",
    "final_ests, vshap_ests_model, vshap_ests_CV, corr_ests = obj_kshap_dep\n",
    "order = np.argsort(np.abs(final_ests))[::-1]\n",
    "print(np.round(100*(np.maximum(corr_ests,0)**2)[order])) # Variance reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "768407c71a286f507fab4bce553d71b5cbd766c247b76eb598ef769225202bc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.16 ('shap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
